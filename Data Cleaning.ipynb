{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91797c51",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "51cbba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing of library\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import re\n",
    "from email import message_from_string\n",
    "from email.utils import parseaddr\n",
    "from typing import List, Optional, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c8c3805c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the data\n",
    "data_chunk = pd.read_csv('emails.csv', chunksize=10000)  # read 10k rows at a time\n",
    "dataset = pd.concat([chunk for chunk in data_chunk]) # concatenate all chunks into a single DataFrame\n",
    "\n",
    "# Display the dataset\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3b72d",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Exploring the dataset helps us better understand its structure and characteristics.\n",
    "\n",
    "This dataset contains approximately **517,401 emails** from about 150 Enron employees, mostly senior management. It was originally collected and prepared by the CALO Project and later made public by the Federal Energy Regulatory Commission during its investigation. Some messages were deleted or redacted, and invalid email addresses were standardized. This dataset does **not include attachments**.  \n",
    "\n",
    "For this section, we will follow these steps:\n",
    "\n",
    "1. Access a sample email from the dataset (first, middle, and last)  \n",
    "2. Generate descriptive statistics  \n",
    "3. Handle missing/null values  \n",
    "4. Check for duplicate rows  \n",
    "5. Check for empty emails  \n",
    "6. Check for emails containing non-ASCII characters  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be02314",
   "metadata": {},
   "source": [
    "### Accessing Sample Emails from the Dataset (First, Middle, and Last)\n",
    "\n",
    "The dataset contains 517,401 rows (indexed 0 to 517,400).  \n",
    "We will examine the first, middle, and last emails to inspect their structure and determine the cleaning steps required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "702b84be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the first email at index 0\n",
    "print(dataset[\"message\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e85787fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <6456001.1075840867645.JavaMail.evans@thyme>\n",
      "Date: Wed, 11 Jul 2001 13:22:18 -0700 (PDT)\n",
      "From: jean.mrha@enron.com\n",
      "To: louise.kitchen@enron.com\n",
      "Subject: Hot List Update\n",
      "Cc: tammie.schoppe@enron.com, melissa.jones@enron.com\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "Bcc: tammie.schoppe@enron.com, melissa.jones@enron.com\n",
      "X-From: Mrha, Jean </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JMRHA>\n",
      "X-To: Kitchen, Louise </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lkitchen>\n",
      "X-cc: Schoppe, Tammie </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tstaggs>, Jones, Melissa </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Mjones1>\n",
      "X-bcc: \n",
      "X-Folder: \\ExMerge - Kitchen, Louise\\'Americas\\Mrha\n",
      "X-Origin: KITCHEN-L\n",
      "X-FileName: louise kitchen 2-7-02.pst\n",
      "\n",
      "Please see attached.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the middle email at index 258700\n",
    "print(dataset[\"message\"][258700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8cc27fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <28618979.1075842030037.JavaMail.evans@thyme>\n",
      "Date: Mon, 26 Nov 2001 10:48:43 -0800 (PST)\n",
      "From: john.zufferli@enron.com\n",
      "To: livia_zufferli@monitor.com\n",
      "Subject: RE: ali's essays\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Zufferli, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JZUFFER>\n",
      "X-To: 'Livia_Zufferli@Monitor.com@ENRON'\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\ExMerge - Zufferli, John\\Sent Items\n",
      "X-Origin: ZUFFERLI-J\n",
      "X-FileName: john zufferli 6-26-02.PST\n",
      "\n",
      "i think the YMCA has a class that is for people recovering from heart-attacks\n",
      "i remeber something about that\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tLivia_Zufferli@Monitor.com@ENRON  \n",
      "Sent:\tMonday, November 26, 2001 11:44 AM\n",
      "To:\tZufferli, John\n",
      "Subject:\tRE: ali's essays\n",
      "\n",
      "\n",
      "i don't know about the heart classes.  i'll look into it, but her dr (ravi)\n",
      "isn't offering up any suggestions or anything.  she saw him before the\n",
      "surgery in august, and he said things were okay.  i really don't think he's\n",
      "too helpful.\n",
      "\n",
      "she is lazy -- but it really frustrates me that she doesn't want to help\n",
      "herself.  i told her that not walking is like not taking her heart\n",
      "medication.  that didn't seem to resonate.  dad is going to go to the YMCA\n",
      "tomorrow and maybe get a membership for both of them -- they have a walking\n",
      "track there (at least it's something to do in the winter).  when she was\n",
      "down this weekend, we walked around the craft show (at the Exhibition\n",
      "place) and she said that was a lot of exercise (2 hrs).  The only problem\n",
      "is that we were just strolling, and not really walking very fast.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    John.Zufferli@\n",
      "                    enron.com            To:     Livia_Zufferli@Monitor.com\n",
      "                                         cc:\n",
      "                    11/26/2001           Subject:     RE: ali's essays\n",
      "                    01:41 PM\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "just send the essay at home\n",
      "\n",
      "I don't know what to do about mom, i don't think fear is the only thing\n",
      "holding her back , i think she is lazy\n",
      "\n",
      "is there a heart health class in Sudbury that has excercise regimines as\n",
      "well as diets?\n",
      "\n",
      "when is the last time she saw her doctor\n",
      "\n",
      "    -----Original Message-----\n",
      "   From:   Livia_Zufferli@Monitor.com@ENRON\n",
      "   Sent:   Monday, November 26, 2001 11:19 AM\n",
      "   To:     Zufferli, John\n",
      "   Subject:  ali's essays\n",
      "\n",
      "   Hi John\n",
      "\n",
      "   How was Thanksgiving?  Was the baby shower fun?\n",
      "\n",
      "   I was wondering if you'd have some time to read over Ali's Chicago\n",
      "   essays\n",
      "   later tonight?  He's going to submit them on Wednesday.  Let me know if\n",
      "   that's okay.  Do you have a printer at home?  Can I send them to your\n",
      "   home\n",
      "   account?  (I don't think Ali will be done before about 8pm or so\n",
      "   tonight).\n",
      "\n",
      "   PS:  We need to talk about mom.  I saw her this weekend -- she's gained\n",
      "   a\n",
      "   lot of weight, and hasn't been exercising at all.  Dad's pretty\n",
      "   frustrated\n",
      "   because all she does is watch tv.  I had a talk with her yesterday\n",
      "   telling\n",
      "   her that she has more risk of having a heart attack if she doesn't walk\n",
      "   /\n",
      "   exercise than if she exerts herself when exercising (i think she's\n",
      "   afraid\n",
      "   of having a heart attack while exercising).  We need to do something --\n",
      "   she's 170lbs now, and should be at around 140lbs to be healthy.\n",
      "\n",
      "   Livia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**********************************************************************\n",
      "This e-mail is the property of Enron Corp. and/or its relevant affiliate\n",
      "and may contain confidential and privileged material for the sole use of\n",
      "the intended recipient (s). Any review, use, distribution or disclosure by\n",
      "others is strictly prohibited. If you are not the intended recipient (or\n",
      "authorized to receive for the recipient), please contact the sender or\n",
      "reply to Enron Corp. at enron.messaging.administration@enron.com and delete\n",
      "all copies of the message. This e-mail (and any attachments hereto) are not\n",
      "intended to be an offer (or an acceptance) and do not create or evidence a\n",
      "binding and enforceable contract between Enron Corp. (or any of its\n",
      "affiliates) and the intended recipient or any other party, and may not be\n",
      "relied on by anyone as the basis of a contract by estoppel or otherwise.\n",
      "Thank you.\n",
      "**********************************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the last email at index 517400\n",
    "print(dataset[\"message\"][517400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d8928",
   "metadata": {},
   "source": [
    "From inspecting the first, middle, and last emails, we can see the general structure and content of the dataset.  \n",
    "\n",
    "Key observations include:\n",
    "- Emails contain extensive headers and metadata, which are not needed for text analysis.\n",
    "- Some emails may have empty subjects or body content.\n",
    "- There is inconsistent formatting, including line breaks, tabs, and spaces, which will need cleaning.\n",
    "- All emails appear to use standard ASCII encoding, but we will still check for encoding issues.\n",
    "\n",
    "These insights help us identify potential issues and guide the next steps in cleaning and parsing the dataset. Before proceeding, we will continue with data exploration to gain a better understanding of the dataset.\n",
    "\n",
    "### Descriptive Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c7a11f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517401, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make a copy to prevent mutation\n",
    "# dataset_ds = dataset.copy()\n",
    "\n",
    "# Shape of dataset\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "224aaf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517401 entries, 0 to 517400\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   file     517401 non-null  object\n",
      " 1   message  517401 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d26be4",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8613c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file       0\n",
      "message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "print(dataset.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30716bd",
   "metadata": {},
   "source": [
    "### Check for Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9a26bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (517401, 2)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "dataset = dataset.drop_duplicates(subset=[\"message\"]).reset_index(drop=True)\n",
    "\n",
    "# Shape of dataset after removing duplicates\n",
    "print(f\"Shape after removing duplicates: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972cc1a",
   "metadata": {},
   "source": [
    "Based on the dataset summary from `info()`, all 517,401 emails have non-null values, so there are no missing entries.  However, this does not guarantee that all emails contain meaningful content, as some messages could be completely empty.  Therefore, we perform a check to identify any emails with empty message bodies.\n",
    "\n",
    "### Check for empty emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8afef5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of completely empty emails: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for completely empty emails without removing spaces for parsing\n",
    "empty_rows = dataset[dataset['message'] == \"\"]\n",
    "print(f\"Number of completely empty emails: {empty_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef67be9",
   "metadata": {},
   "source": [
    "### Check to see if there is any emails in non-ASCII Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a8ee406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails with non-ASCII characters: 90\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a text contains any non-ASCII characters\n",
    "def has_non_ascii(text):\n",
    "    return any(ord(c) > 127 for c in str(text))\n",
    "\n",
    "# Apply to the 'message' column\n",
    "non_ascii_rows = dataset[dataset['message'].apply(has_non_ascii)]\n",
    "print(f\"Number of emails with non-ASCII characters: {non_ascii_rows.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b0bfc22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <13235995.1075840348885.JavaMail.evans@thyme>\n",
      "Date: Wed, 23 Jan 2002 19:39:18 -0800 (PST)\n",
      "From: bgibson50606@houston.rr.com\n",
      "To: sumpter.teresa@enron.com, stone.pam@enron.com, smithey.linda@enron.com, \n",
      "\tsinitiere.mary�nelle@enron.com, shrode.cindy@enron.com, \n",
      "\tshort.suzanne@enron.com, scardello.jackie@enron.com, \n",
      "\troberts.gina@enron.com, richmond.trisch@enron.com, \n",
      "\treese.lisa@enron.com, ramsey.nancy@enron.com, \n",
      "\tpurser.brenda@enron.com, price.lisa@enron.com, price.jane@enron.com, \n",
      "\tpoullard.marie@enron.com, podraza.judy@enron.com, \n",
      "\tpetrak.janet@enron.com, pearce.becky@enron.com, \n",
      "\tpauley.sharon@enron.com, passero.colleen@enron.com, \n",
      "\torgan.kathryn@enron.com, munn.mary@enron.com, morgan.tia@enron.com, \n",
      "\tmontalvo.meg@enron.com, molohon.nora@enron.com, mikel.val@enron.com, \n",
      "\tmcmullen.katie@enron.com, mclaughlin.patricia@enron.com, \n",
      "\tmcguinness.lori@enron.com, mcdaniel.teri@enron.com, \n",
      "\tmccracken.claudia@enron.com, matthews.patricia�@enron.com, \n",
      "\tmartin.joy@enron.com, marshall.sarah@enron.com, \n",
      "\tmark.elaine@enron.com, lyons.gayle@enron.com, loria.claire@enron.com, \n",
      "\tloggins.susan@enron.com, lindsey.barbara@enron.com, \n",
      "\tleal.carmen@enron.com, kreiner.linda@enron.com, \n",
      "\tklingsporn.donah@enron.com, klatt.lori@enron.com, \n",
      "\tking.kathy@enron.com, khanna.anjali@enron.com, \n",
      "\tkapasi.anhar@enron.com, jortner.sheila@enron.com, \n",
      "\tjones.barbara@enron.com, johnson.kelly@enron.com, \n",
      "\tisgett.devonne@enron.com, holub.kay@enron.com, \n",
      "\tholmes.gayle@enron.com, hoing.debbie@enron.com, \n",
      "\thodge.vicki@enron.com, hartzog.janet@enron.com, \n",
      "\thaney.susan@enron.com, gregory.colleen@enron.com, \n",
      "\tglenn.tia@enron.com, glapa.kathlene@enron.com, \n",
      "\tgladstein.robin@enron.com, gibson.beverly@enron.com, \n",
      "\tgalante.nancy@enron.com, fritz.margaret@enron.com, \n",
      "\tewalt.lori@enron.com, ellis.michele@enron.com, \n",
      "\tdufrene.lynette@enron.com, doran.maggie@enron.com, \n",
      "\tdipaolo.nancy@enron.com, denton.diana@enron.com, \n",
      "\tday.cynthia@enron.com, craddock.gay@enron.com, \n",
      "\tconnell.linda@enron.com, christy.linda@enron.com, \n",
      "\tchabaud.peggy@enron.com, byrd.sandy@enron.com, \n",
      "\tbuckley.miranda@enron.com, broadus.therese@enron.com, \n",
      "\tbritton.joan@enron.com, black.kathy@enron.com, \n",
      "\tbillman.sharlane@enron.com, bell.teresa@enron.com, \n",
      "\tbell.connie@enron.com, sally.beck@enron.com, bauer.gina@enron.com, \n",
      "\tbarger.jean@enron.com, baker.karen@enron.com, assour.cindy@enron.com, \n",
      "\tarrington.sue@enron.com, alvarado.sharon@enron.com, \n",
      "\talvarado.estella@enron.com\n",
      "Subject: NCL Philanthropies\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: \"Beverly Gibson\" <bgibson50606@houston.rr.com>@ENRON\n",
      "X-To: Teresa Sumpter <Sumphoust@aol.com>, Pam Stone <RStone9522@aol.com>, Linda Smithey <ges@houston.rr.com>, Mary�Nelle Sinitiere <mns1024@houston.rr.com>, Cindy Shrode <shrode376@aol.com>, Suzanne Short <sjstex@att.net>, Jackie Scardello <Jackie.Scardello@Compaq.com>, Gina Roberts <RobertsM5@aol.com>, Trisch Richmond <trichmond00@hotmail.com>, Lisa Reese <BKReese98@aol.com>, Nancy Ramsey <nramsey@houston.rr.com>, Brenda Purser <Tpurser@houston.rr.com>, Lisa Price <Gemi602@aol.com>, Jane Price <mprice@hia.net>, Marie Poullard <Mr_Clean@SWBell.net>, Judy Podraza <jipod@aol.com>, Janet Petrak <janetpetrak@usa.net>, Becky Pearce <rebachian@hotmail.com>, Sharon Pauley <spauley@SWBell.net>, Colleen Passero <cpassero@houston.rr.com>, Kathryn Organ <DKA4O@aol.com>, Mary Munn <MMUNN@family.net>, Tia Morgan <TFMMO@aol.com>, Meg Montalvo <Montalvo97@aol.com>, Nora Molohon <rmolohon@pdq.net>, Val Mikel <mikl@texas.net>, Katie McMullen <KatieMcmullen@aol.com>, Patricia McLaughlin <PatriciaM@houston.rr.com>, Lori McGuinness <thomasmc@msn.com>, Teri McDaniel <DAnz7MNM@aol.com>, Claudia McCracken <claudia.mccracken@Compaq.com>, Patricia� Matthews <Trish@Quadcitys.com>, Joy Martin <MJoyMartin@aol.com>, Sarah Marshall <sarahm@flex.net>, Elaine Mark <tegamark@ix.netcom.com>, Gayle Lyons <Lauraly1386@aol.com>, Claire Loria <Momcat5cwl@aol.com>, Susan Loggins <sklduece@aol.com>, Barbara Lindsey <BabsLind@aol.com>, Carmen Leal <ECMCCH@aol.com>, Linda Kreiner <tkreiner1@worldnet.att.net>, Donah Klingsporn <bklingsporn@houston.rr.com>, Lori Klatt <jklatt@houston.rr.com>, Kathy King <kathytx@hotmail.com>, Anjali Khanna <dakhanna@hotmail.com>, Anhar Kapasi <abbasak@aol.com>, Sheila Jortner <jortner@ev1.net>, Barbara Jones <bwjski@aol.com>, Kelly Johnson <jfriends@clearsail.net>, Devonne Isgett <ESI0001@aol.com>, Kay Holub <KLHolub@aol.com>, Gayle Holmes <RCHOLMES13@yahoo.com>, Debbie Hoing <sdhoing@aol.com>, Vicki Hodge <jhodge7895@aol.com>, Janet Hartzog <Ketchup1200@aol.com>, Susan Haney <slynneh2@aol.com>, Colleen Gregory <colleen_gregory@hotmail.com>, Tia Glenn <TGlenn8246@cs.com>, Kathlene Glapa <kglapa@pdq.net>, Robin Gladstein <rgladstein@aol.com>, Beverly Gibson <bgibson50606@yahoo.com>, Nancy Galante <ncgalante@aol.com>, Margaret Fritz <dannyfritz@worldnet.att.net>, Lori Ewalt <lewalt53@aol.com>, Michele Ellis <mellis@pdq.net>, Lynette Dufrene <CDMcandles@aol.com>, Maggie Doran <madjad@flash.net>, Nancy DiPaolo <JNKMDip@aol.com>, Diana Denton <dianaLD101@aol.com>, Cynthia Day <cday@houston.rr.com>, Gay Craddock <jcraddock@ev1.net>, Linda Connell <jgconn@yahoo.com>, Linda Christy <linda@thechristys.net>, Peggy Chabaud <luckynumber44@hotmail.com>, Sandy Byrd <markandsandybyrd@msn.com>, Miranda Buckley <MirandaBuckley@PZLQS.com>, Therese Broadus <luvzakc@aol.com>, Joan Britton <JoanBrtt@netscape.net>, Kathy Black <kblack@aokcomputers.com>, Sharlane Billman <gsetbill@gateway.net>, Teresa Bell <tgallagherbell@msn.com>, Connie Bell <KBSPIKE@aol.com>, Beck, Sally </O=ENRON/OU=NA/CN=RECIPIENTS/CN=SBECK>, Gina Bauer <Bauer_John@msn.com>, Jean Barger <jbiz@flash.net>, Karen Baker <Birdie5263@aol.com>, Cindy Assour <swmfly@telocity.com>, Sue Arrington <bettyboop021457@aol.com>, Sharon Alvarado <SJA103@aol.com>, Estella Alvarado <Eda311@aol.com>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\sbeck\\Deleted Items\n",
      "X-Origin: BECK-S\n",
      "X-FileName: sally beck 1-28-02.pst\n",
      "\n",
      "\n",
      "Membership:  Please remember that we have commitments to our  philanthropies even though you may have completed your hours.  We are in  need for people to sign up for: \n",
      "KEEP PACE TRANSITION NIGHT \n",
      "Tuesday,  January 29; 6:30 p.m. - 8:30 p.m. \n",
      "Call Jane Price at 281-587-1990  \n",
      "Atria Retirement Home - Bingo and Painting, Call Diana Denton for dates  (281-370-6765).\n",
      " \n",
      "-Claire  Loria\n"
     ]
    }
   ],
   "source": [
    "print(non_ascii_rows[\"message\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d6bc5",
   "metadata": {},
   "source": [
    "\n",
    "Based on the data exploration, we observed that the dataset contains no null values, no duplicate rows, and no completely empty emails. However, we did identify a small number of emails containing non-ASCII characters. Since we are building a phishing email detection system, we have decided **not to remove these emails** and will handle them appropriately during system development. We believe this is beneficial, as these emails may help detect unusual or potentially suspicious messages while also verifying legitimate ones.  \n",
    "\n",
    "Next, we proceed to clean the dataset to prepare the emails for parsing and analysis.\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "In this section, we will clean the dataset using several methods:\n",
    "\n",
    "1. Email Parsing  \n",
    "2. Text Cleaning\n",
    "3. Post-Parsing Data Checks\n",
    "\n",
    "**Email parsing** involves extracting the meaningful content from each email, such as the body text, while removing unnecessary components like headers, metadata, or special formatting.\n",
    "\n",
    "This step is essential to prepare the emails for further cleaning, analysis, or natural language processing tasks.\n",
    "\n",
    "\n",
    "### Email Parsing\n",
    "Email parsing is essential to extract structured information from raw emails.  \n",
    "We will split this process into three main sections:\n",
    "\n",
    "1. **Header extraction:** Important fields like `Message-ID`, `Date`, `From`, `To`, `Subject`, `X-From`, and `X-To` will be extracted from the email headers.   \n",
    "2. **Message body extraction:** The main content of the email will be isolated for further analysis, including text cleaning and phishing detection. \n",
    "3. **URL extraction:** Links are crucial for identifying suspicious or malicious content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2078c16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Message-ID', '<18782981.1075855378110.JavaMail.evans@thyme>'),\n",
       " ('Date', 'Mon, 14 May 2001 16:39:00 -0700 (PDT)'),\n",
       " ('From', 'phillip.allen@enron.com'),\n",
       " ('To', 'tim.belden@enron.com'),\n",
       " ('Subject', ''),\n",
       " ('Mime-Version', '1.0'),\n",
       " ('Content-Type', 'text/plain; charset=us-ascii'),\n",
       " ('Content-Transfer-Encoding', '7bit'),\n",
       " ('X-From', 'Phillip K Allen'),\n",
       " ('X-To', 'Tim Belden <Tim Belden/Enron@EnronXGate>'),\n",
       " ('X-cc', ''),\n",
       " ('X-bcc', ''),\n",
       " ('X-Folder', \"\\\\Phillip_Allen_Jan2002_1\\\\Allen, Phillip K.\\\\'Sent Mail\"),\n",
       " ('X-Origin', 'Allen-P'),\n",
       " ('X-FileName', 'pallen (Non-Privileged).pst')]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the email into correct format\n",
    "message = dataset.loc[0]['message']\n",
    "e = message_from_string(message)\n",
    "\n",
    "e.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb65cb8",
   "metadata": {},
   "source": [
    "After inspecting the content of a sample email, we observed that each email contains useful information in its headers, such as `Message-ID`, `Date`, `From`, `To`, `Subject`, and employee metadata (`X-From`, `X-To`).  \n",
    "\n",
    "To facilitate further analysis and rule-based phishing detection, we decided to extract these fields from all emails and store them in a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2f5ab547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing emails: 100%|██████████| 517401/517401 [00:00<00:00, 2081155.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_email(raw_msg: Any, fields: Optional[List[str]] = None) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Parse a raw email string and extract specified header fields.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_msg : str\n",
    "        The raw email content as a string.\n",
    "    fields : list[str], optional\n",
    "        List of email fields to extract. Default includes common fields.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping field names to extracted values (or None if missing).\n",
    "    \"\"\"\n",
    "    if fields is None:\n",
    "        fields = [\"Message-ID\", \"Date\", \"From\", \"To\", \"Subject\", \"X-From\", \"X-To\"]\n",
    "\n",
    "    try:\n",
    "        email_obj = message_from_string(raw_msg)\n",
    "        return {field.lower().replace(\"-\", \"_\"): email_obj.get(field) \n",
    "                for field in fields}\n",
    "    except Exception:\n",
    "        # Return None for all fields if parsing fails\n",
    "        return {field.lower().replace(\"-\", \"_\"): None for field in fields}\n",
    "\n",
    "\n",
    "def build_email_dataframe(df: pd.DataFrame, message_col: str = \"message\", fields: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract structured fields from raw email messages in a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing a column of raw email text.\n",
    "    message_col : str\n",
    "        Column name containing raw email strings.\n",
    "    fields : list[str], optional\n",
    "        Fields to extract from each email.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with extracted email fields.\n",
    "    \"\"\"\n",
    "    # tqdm progress bar for large datasets\n",
    "    parsed = df[message_col].apply(lambda msg: parse_email(msg, fields))\n",
    "    parsed = list(tqdm(parsed, total=len(df), desc=\"Parsing emails\"))\n",
    "    return pd.DataFrame(parsed)\n",
    "\n",
    "# Extract fields from the raw message column using the build_email_dataframe function\n",
    "extracted_df = build_email_dataframe(dataset, message_col=\"message\") # Did not specify fields, so default fields will be extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d669df4",
   "metadata": {},
   "source": [
    "#### Message Body Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fec54334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def body(messages):\n",
    "    column = []\n",
    "    for message in messages:\n",
    "        e = message_from_string(message)\n",
    "        column.append(e.get_payload())\n",
    "    return column\n",
    "\n",
    "extracted_df['body'] = body(dataset['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67585a",
   "metadata": {},
   "source": [
    "### Validation of Body and Header Extraction  \n",
    "\n",
    "After extracting the body of each email, it is important to validate the results. Due to inconsistencies and formatting issues within the Enron dataset, some emails may not parse correctly. This can lead to:  \n",
    "\n",
    "1. **Incomplete or incorrect body extraction**  \n",
    "   - In certain cases, parts of the email headers may still remain inside the `body` field instead of being fully separated.  \n",
    "   - This requires manual or programmatic checks to confirm that the `body` column truly contains only the message content.  \n",
    "\n",
    "2. **Null or missing values in headers**  \n",
    "   - Some header fields such as `to`, `from`, or `subject` may appear as null after parsing.  \n",
    "   - These values may still exist within the raw email text but were not properly extracted during parsing.  \n",
    "\n",
    "To address this, we will:  \n",
    "- Inspect a sample of emails to verify that the `body` field contains the actual message rather than residual headers.  \n",
    "- Cross-check the raw `message` text for cases where header fields (e.g., `to`) are null, and attempt to recover these values if possible.  \n",
    "\n",
    "This step ensures that the dataset is **accurately structured** before proceeding to further cleaning and analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1a49c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to clean body after last X-FileName and recover X-From / X-To if present\n",
    "# def clean_body_after_xfilename(raw_body):\n",
    "#     \"\"\"\n",
    "#     Process order:\n",
    "#       1) Normalize newlines and split into lines.\n",
    "#       2) Scan ALL lines first to recover X-From / X-To (case-insensitive).\n",
    "#       3) Find the last 'X-FileName:' anchor and take the body ONLY after it.\n",
    "#       4) From that slice, drop any residual X-From / X-To lines.\n",
    "#       5) Join and trim → return (body_clean, recovered_dict).\n",
    "#     \"\"\"\n",
    "#     if raw_body is None:\n",
    "#         return \"\", {}\n",
    "\n",
    "#     # 1) Normalize newlines and split into lines\n",
    "#     lines = str(raw_body).replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").split(\"\\n\")\n",
    "\n",
    "#     # 2) Recover X-From / X-To from ANYWHERE in the text (headers/body)\n",
    "#     recovered = {}\n",
    "#     xhdr = re.compile(r'^(x-from|x-to)\\s*:\\s*(.*)$', re.IGNORECASE)\n",
    "#     for ln in lines:\n",
    "#         m = xhdr.match(ln.strip())\n",
    "#         if m:\n",
    "#             key = m.group(1).lower().replace(\"-\", \"_\")   # -> \"x_from\" / \"x_to\"\n",
    "#             recovered[key] = m.group(2).strip()\n",
    "\n",
    "#     # 3) Find last 'X-FileName:' anchor; body starts AFTER this line\n",
    "#     anchor_idx = -1\n",
    "#     for i, ln in enumerate(lines):\n",
    "#         if re.match(r'(?i)^x-filename\\s*:', ln.strip()):\n",
    "#             anchor_idx = i\n",
    "#     body_slice = lines[anchor_idx + 1:] if anchor_idx >= 0 else lines\n",
    "\n",
    "#     # 4) From the body slice, drop any X-From / X-To lines (we’ve already captured them)\n",
    "#     kept = []\n",
    "#     for ln in body_slice:\n",
    "#         if xhdr.match(ln.strip()):\n",
    "#             continue\n",
    "#         kept.append(ln)\n",
    "\n",
    "#     # 5) Join → tidy a bit (optional) → return\n",
    "#     body = \"\\n\".join(kept).strip()\n",
    "#     return body, recovered\n",
    "\n",
    "# # ensure columns exist\n",
    "# for col in (\"x_from\", \"x_to\"):\n",
    "#     if col not in extracted_df.columns:\n",
    "#         extracted_df[col] = np.nan\n",
    "\n",
    "# clean_bodies = []\n",
    "# filled_from = filled_to = 0\n",
    "\n",
    "# for i, msg in enumerate(extracted_df[\"body\"]):  \n",
    "#     body_clean, rec = clean_body_after_xfilename(msg)\n",
    "#     clean_bodies.append(body_clean)\n",
    "\n",
    "#     if \"x_from\" in rec and (pd.isna(extracted_df.at[i, \"x_from\"]) or str(extracted_df.at[i, \"x_from\"]).strip() == \"\"):\n",
    "#         extracted_df.at[i, \"x_from\"] = rec[\"x_from\"]; filled_from += 1\n",
    "#     if \"x_to\" in rec and (pd.isna(extracted_df.at[i, \"x_to\"]) or str(extracted_df.at[i, \"x_to\"]).strip() == \"\"):\n",
    "#         extracted_df.at[i, \"x_to\"] = rec[\"x_to\"];     filled_to += 1\n",
    "\n",
    "# extracted_df[\"body\"] = clean_bodies\n",
    "# print(f\"Filled x_from in {filled_from} rows; x_to in {filled_to} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filled_x_from': 29, 'filled_x_to': 29, 'rows': 517401}\n"
     ]
    }
   ],
   "source": [
    "# --- core: parse one body string ---\n",
    "def extract_body_and_x(body_text: str):\n",
    "    \"\"\"\n",
    "    Returns (clean_body, x_from, x_to).\n",
    "\n",
    "    Steps (simple):\n",
    "    1) Normalize newlines and split into lines.\n",
    "    2) Remember the last seen 'X-From:' and 'X-To:' (anywhere).\n",
    "    3) Body starts AFTER the last 'X-FileName:' line.\n",
    "    4) Remove any X-From/X-To lines from that body slice.\n",
    "    \"\"\"\n",
    "    if body_text is None:\n",
    "        return \"\", None, None\n",
    "\n",
    "    # 1) normalize & split\n",
    "    lines = str(body_text).replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").split(\"\\n\")\n",
    "\n",
    "    # 2) capture X-From / X-To (keep last value if multiple)\n",
    "    x_from = x_to = None\n",
    "    xhdr = re.compile(r'^(x-from|x-to)\\s*:\\s*(.*)$', re.IGNORECASE)\n",
    "    for ln in lines:\n",
    "        m = xhdr.match(ln.strip())\n",
    "        if m:\n",
    "            key, val = m.group(1).lower(), m.group(2).strip()\n",
    "            if key == \"x-from\": x_from = val\n",
    "            else:               x_to   = val\n",
    "\n",
    "    # 3) find last 'X-FileName:' anchor; body starts after it\n",
    "    anchor = -1\n",
    "    for i, ln in enumerate(lines):\n",
    "        if re.match(r'(?i)^x-filename\\s*:', ln.strip()):\n",
    "            anchor = i\n",
    "    body_slice = lines[anchor + 1:] if anchor >= 0 else lines\n",
    "\n",
    "    # 4) drop any X-From/X-To lines from body\n",
    "    kept = [ln for ln in body_slice if not xhdr.match(ln.strip())]\n",
    "    body_clean = \"\\n\".join(kept).strip()\n",
    "\n",
    "    return body_clean, x_from, x_to\n",
    "\n",
    "\n",
    "# --- apply to a dataframe (reusable wrapper) ---\n",
    "def apply_extract_body_and_x(df: pd.DataFrame,\n",
    "                             body_col: str = \"body\",\n",
    "                             x_from_col: str = \"x_from\",\n",
    "                             x_to_col: str = \"x_to\") -> dict:\n",
    "    \"\"\"\n",
    "    Cleans df[body_col], fills missing x_from/x_to, and returns counts.\n",
    "    - Updates df[body_col] in place with the cleaned body.\n",
    "    - Creates x_from/x_to columns if they don't exist.\n",
    "    - Fills only where current value is empty/NaN.\n",
    "    \"\"\"\n",
    "    # ensure target columns exist\n",
    "    for col in (x_from_col, x_to_col):\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # run once, expand into columns\n",
    "    res = df[body_col].apply(extract_body_and_x).apply(pd.Series)\n",
    "    res.columns = [\"__body_tmp__\", \"__x_from_tmp__\", \"__x_to_tmp__\"]\n",
    "\n",
    "    # helper: is empty cell?\n",
    "    is_empty = lambda s: s.isna() | (s.astype(str).str.strip() == \"\")\n",
    "\n",
    "    # fill counts\n",
    "    mask_from = is_empty(df[x_from_col]) & res[\"__x_from_tmp__\"].notna()\n",
    "    mask_to   = is_empty(df[x_to_col])   & res[\"__x_to_tmp__\"].notna()\n",
    "\n",
    "    # update df\n",
    "    df.loc[:, body_col] = res[\"__body_tmp__\"]\n",
    "    df.loc[mask_from, x_from_col] = res.loc[mask_from, \"__x_from_tmp__\"]\n",
    "    df.loc[mask_to,   x_to_col]   = res.loc[mask_to,   \"__x_to_tmp__\"]\n",
    "\n",
    "    # cleanup temp cols (not added to df, they are in res only)\n",
    "    return {\n",
    "        \"filled_x_from\": int(mask_from.sum()),\n",
    "        \"filled_x_to\":   int(mask_to.sum()),\n",
    "        \"rows\":          int(len(df))\n",
    "    }\n",
    "\n",
    "stats = apply_extract_body_and_x(extracted_df, body_col=\"body\", x_from_col=\"x_from\", x_to_col=\"x_to\")\n",
    "print(stats)  # {'filled_x_from': 29, 'filled_x_to': 17, 'rows': 517401}  (example numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e2881fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fundamental Overview Presentation\\nFriday, September 21st\\n1 - 3pm\\nroom 32c2'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df['body'][18162]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53bf356",
   "metadata": {},
   "source": [
    "#### URL Extraction\n",
    "\n",
    "Next, we extract all URLs contained in the email bodies.  \n",
    "\n",
    "URLs are important for phishing detection because suspicious or malicious links are often key indicators of phishing attempts.  \n",
    "\n",
    "By isolating the URLs, we can analyze them separately and apply rules to identify potentially harmful links.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6ab6e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract URLs from dataset['message'] directly\n",
    "def extract_urls_from_message(raw_msg):\n",
    "    if not isinstance(raw_msg, str):\n",
    "        return None\n",
    "    url_pattern = r'(https?://[^\\s]+)'\n",
    "    urls = re.findall(url_pattern, raw_msg)\n",
    "    return urls if urls else None\n",
    "\n",
    "# apply directly on the raw message column\n",
    "extracted_df['urls'] = dataset['message'].apply(extract_urls_from_message)\n",
    "extracted_df['num_urls'] = extracted_df['urls'].apply(lambda x: len(x) if x is not None else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b849524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>x_from</th>\n",
       "      <th>x_to</th>\n",
       "      <th>body</th>\n",
       "      <th>urls</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
       "      <td>Here is our forecast</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>Re:</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>leah.arsdall@enron.com</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      message_id  \\\n",
       "0  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    date                     from  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "\n",
       "                        to    subject           x_from  \\\n",
       "0     tim.belden@enron.com             Phillip K Allen   \n",
       "1  john.lavorato@enron.com        Re:  Phillip K Allen   \n",
       "2   leah.arsdall@enron.com   Re: test  Phillip K Allen   \n",
       "3    randall.gay@enron.com             Phillip K Allen   \n",
       "4     greg.piper@enron.com  Re: Hello  Phillip K Allen   \n",
       "\n",
       "                                                x_to  \\\n",
       "0           Tim Belden <Tim Belden/Enron@EnronXGate>   \n",
       "1  John J Lavorato <John J Lavorato/ENRON@enronXg...   \n",
       "2                                   Leah Van Arsdall   \n",
       "3                                      Randall L Gay   \n",
       "4                                         Greg Piper   \n",
       "\n",
       "                                                body  urls  num_urls  \n",
       "0                               Here is our forecast  None         0  \n",
       "1  Traveling to have a business meeting takes the...  None         0  \n",
       "2                     test successful.  way to go!!!  None         0  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  None         0  \n",
       "4                  Let's shoot for Tuesday at 11:45.  None         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows to verify extraction\n",
    "display(extracted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3218dc4",
   "metadata": {},
   "source": [
    "Based on the extracted dataset, all key headers, the email body and URLs have been successfully captured and standardized. The `body` field is readable and normalized, while `message_id` preserves its original format. Although this sample shows no URLs, the dataset is structured to capture them if present in other emails. \n",
    "\n",
    "### Text Cleaning\n",
    "\n",
    "In this step, we clean the relevant text fields in the dataset to prepare for analysis and phishing detection.  \n",
    "\n",
    "The cleaning process includes:\n",
    "1. **Removing content inside angle brackets (`<...>`)** for all columns except `message_id`.  \n",
    "   - This helps standardize email addresses and header fields.  \n",
    "2. **Normalizing whitespace**  \n",
    "   - Multiple spaces, tabs, and newlines are replaced with a single space.  \n",
    "   - Leading and trailing spaces are removed.   \n",
    "3. **Reordering and renaming columns**  \n",
    "   - Adjust column order and names to match the workflow for phishing detection analysis.  \n",
    "   - This makes the dataset more organized and easier to work with for subsequent steps.\n",
    "\n",
    "This ensures all text fields are **clean, consistent, and ready** for further processing, while preserving important information for phishing detection, including URLs, attachments, and non-ASCII characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0c85780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to prevent mutation\n",
    "data_ds = extracted_df.copy()\n",
    "\n",
    "def clean_text(x, keep_tags=False):\n",
    "    \"\"\"\n",
    "    - Collapse whitespace\n",
    "    - Remove <...> entirely unless keep_tags=True\n",
    "    - Remove [] but keep the content inside\n",
    "    - Remove quotes ' and \"\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return None # No change\n",
    "\n",
    "    text = str(x)\n",
    "\n",
    "    if not keep_tags:\n",
    "        text = re.sub(r'<[^>]*>', '', text)      # remove <...>\n",
    "\n",
    "    text = re.sub(r'[\\[\\]\\'\"]+', '', text)       # drop [, ], ', \"\n",
    "\n",
    "    return re.sub(r'\\s+', ' ', text).strip()     # collapse ws + strip\n",
    "\n",
    "# now apply depending on the column \n",
    "for col in ['message_id', 'date', 'from', 'x_from', 'to', 'x_to', 'subject', 'body', 'urls', 'num_urls']:\n",
    "    if col == 'message_id':\n",
    "        data_ds[col] = data_ds[col].apply(lambda x: clean_text(x, keep_tags=True))\n",
    "    else:\n",
    "        data_ds[col] = data_ds[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "292ea6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Remove angle brackets from message_id\n",
    "# data_ds['message_id'] = data_ds['message_id'].str.replace(r'[<>]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a1f1fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns for better readability\n",
    "cols = ['message_id', 'date', 'from', 'x_from', 'to', 'x_to', 'subject', 'body', 'urls', 'num_urls']\n",
    "data_ds = data_ds[cols]\n",
    "\n",
    "# Changing column names for better readability\n",
    "data_ds = data_ds.rename(columns={\n",
    "    'x_from': 'sender',\n",
    "    'x_to': 'recipient'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fa62d7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>sender</th>\n",
       "      <th>to</th>\n",
       "      <th>recipient</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>urls</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "      <td>Tim Belden</td>\n",
       "      <td></td>\n",
       "      <td>Here is our forecast</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>John J Lavorato</td>\n",
       "      <td>Re:</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>leah.arsdall@enron.com</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>test successful. way to go!!!</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td></td>\n",
       "      <td>Randy, Can you send me a schedule of the salar...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>Lets shoot for Tuesday at 11:45.</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      message_id  \\\n",
       "0  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    date                     from  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "\n",
       "            sender                       to         recipient    subject  \\\n",
       "0  Phillip K Allen     tim.belden@enron.com        Tim Belden              \n",
       "1  Phillip K Allen  john.lavorato@enron.com   John J Lavorato        Re:   \n",
       "2  Phillip K Allen   leah.arsdall@enron.com  Leah Van Arsdall   Re: test   \n",
       "3  Phillip K Allen    randall.gay@enron.com     Randall L Gay              \n",
       "4  Phillip K Allen     greg.piper@enron.com        Greg Piper  Re: Hello   \n",
       "\n",
       "                                                body  urls num_urls  \n",
       "0                               Here is our forecast  None        0  \n",
       "1  Traveling to have a business meeting takes the...  None        0  \n",
       "2                      test successful. way to go!!!  None        0  \n",
       "3  Randy, Can you send me a schedule of the salar...  None        0  \n",
       "4                   Lets shoot for Tuesday at 11:45.  None        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the cleaned dataframe\n",
    "display(data_ds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05296e63",
   "metadata": {},
   "source": [
    "### Post-Parsing Data Validation\n",
    "\n",
    "After parsing and splitting the emails into separate columns, it is important to verify the integrity of the new dataset.  \n",
    "\n",
    "We will:\n",
    "\n",
    "1. **Check for null values** – Some fields such as `subject` or `body` may be empty even if the original message was not null.  \n",
    "2. **Check for duplicate rows** – Parsing may create redundant entries that should be removed.  \n",
    "3. **Inspect dataset summary** – Using `data.info()` to review column names, data types, and non-null counts.  \n",
    "\n",
    "These steps ensure that the parsed dataset is **clean, consistent, and ready** for further analysis and phishing detection.\n",
    "\n",
    "#### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ab8cb102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517401 entries, 0 to 517400\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   message_id  517401 non-null  object\n",
      " 1   date        517401 non-null  object\n",
      " 2   from        517401 non-null  object\n",
      " 3   sender      517401 non-null  object\n",
      " 4   to          495554 non-null  object\n",
      " 5   recipient   517401 non-null  object\n",
      " 6   subject     517401 non-null  object\n",
      " 7   body        517401 non-null  object\n",
      " 8   urls        67121 non-null   object\n",
      " 9   num_urls    517401 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 39.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the info of cleaned dataframe\n",
    "data_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0863011",
   "metadata": {},
   "source": [
    "##### Handling of Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d948b2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message_id         0\n",
      "date               0\n",
      "from               0\n",
      "sender             0\n",
      "recipient          0\n",
      "subject            0\n",
      "body               0\n",
      "num_urls           0\n",
      "to             21847\n",
      "urls          450280\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "print(data_ds.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f69b537",
   "metadata": {},
   "source": [
    "##### Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0ecabbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (517401, 10)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "data_ds = data_ds.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Shape of dataset after removing duplicates\n",
    "print(f\"Shape after removing duplicates: {data_ds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b646778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a copy to prevent mutation\n",
    "# data_ds = extracted_df.copy()\n",
    "\n",
    "# def clean_text(x, keep_tags=False):\n",
    "#     \"\"\"\n",
    "#     - Collapse whitespace\n",
    "#     - Remove <...> entirely unless keep_tags=True\n",
    "#     - Remove [] but keep the content inside\n",
    "#     - Remove quotes ' and \"\n",
    "#     \"\"\"\n",
    "#     if x is None:\n",
    "#         return None # No change\n",
    "\n",
    "#     text = str(x)\n",
    "\n",
    "#     if not keep_tags:\n",
    "#         text = re.sub(r'<[^>]*>', '', text)      # remove <...>\n",
    "\n",
    "#     text = re.sub(r'[\\[\\]\\'\"]+', '', text)       # drop [, ], ', \"\n",
    "\n",
    "#     return re.sub(r'\\s+', ' ', text).strip()     # collapse ws + strip\n",
    "\n",
    "# clean_text('Baughman Jr., Don </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DBAUGHM>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a6c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
