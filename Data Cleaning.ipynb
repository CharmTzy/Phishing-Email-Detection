{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91797c51",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51cbba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing of library\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "from email import message_from_string\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736c3bc",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c3805c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the data\n",
    "data_chunk = pd.read_csv('emails.csv', chunksize=10000)  # read 10k rows at a time\n",
    "dataset = pd.concat([chunk for chunk in data_chunk]) # concatenate all chunks into a single DataFrame\n",
    "\n",
    "# Display the dataset\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3b72d",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Exploring the dataset helps us better understand its structure and characteristics.\n",
    "\n",
    "This dataset contains approximately **517,401 emails** from about 150 Enron employees, mostly senior management. It was originally collected and prepared by the CALO Project and later made public by the Federal Energy Regulatory Commission during its investigation. Some messages were deleted or redacted, and invalid email addresses were standardized. This dataset does **not include attachments**.  \n",
    "\n",
    "For this section, we will follow these steps:\n",
    "\n",
    "1. Access a sample email from the dataset (first, middle, and last)  \n",
    "2. Generate descriptive statistics  \n",
    "3. Handle missing/null values  \n",
    "4. Check for duplicate rows  \n",
    "5. Check for empty emails  \n",
    "6. Check for emails containing non-ASCII characters  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be02314",
   "metadata": {},
   "source": [
    "### Accessing Sample Emails from the Dataset (First, Middle, and Last)\n",
    "\n",
    "The dataset contains 517,401 rows (indexed 0 to 517,400).  \n",
    "We will examine the first, middle, and last emails to inspect their structure and determine the cleaning steps required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702b84be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the first email at index 0\n",
    "print(dataset[\"message\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e85787fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <6456001.1075840867645.JavaMail.evans@thyme>\n",
      "Date: Wed, 11 Jul 2001 13:22:18 -0700 (PDT)\n",
      "From: jean.mrha@enron.com\n",
      "To: louise.kitchen@enron.com\n",
      "Subject: Hot List Update\n",
      "Cc: tammie.schoppe@enron.com, melissa.jones@enron.com\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "Bcc: tammie.schoppe@enron.com, melissa.jones@enron.com\n",
      "X-From: Mrha, Jean </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JMRHA>\n",
      "X-To: Kitchen, Louise </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lkitchen>\n",
      "X-cc: Schoppe, Tammie </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tstaggs>, Jones, Melissa </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Mjones1>\n",
      "X-bcc: \n",
      "X-Folder: \\ExMerge - Kitchen, Louise\\'Americas\\Mrha\n",
      "X-Origin: KITCHEN-L\n",
      "X-FileName: louise kitchen 2-7-02.pst\n",
      "\n",
      "Please see attached.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the middle email at index 258700\n",
    "print(dataset[\"message\"][258700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc27fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <28618979.1075842030037.JavaMail.evans@thyme>\n",
      "Date: Mon, 26 Nov 2001 10:48:43 -0800 (PST)\n",
      "From: john.zufferli@enron.com\n",
      "To: livia_zufferli@monitor.com\n",
      "Subject: RE: ali's essays\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Zufferli, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JZUFFER>\n",
      "X-To: 'Livia_Zufferli@Monitor.com@ENRON'\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\ExMerge - Zufferli, John\\Sent Items\n",
      "X-Origin: ZUFFERLI-J\n",
      "X-FileName: john zufferli 6-26-02.PST\n",
      "\n",
      "i think the YMCA has a class that is for people recovering from heart-attacks\n",
      "i remeber something about that\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tLivia_Zufferli@Monitor.com@ENRON  \n",
      "Sent:\tMonday, November 26, 2001 11:44 AM\n",
      "To:\tZufferli, John\n",
      "Subject:\tRE: ali's essays\n",
      "\n",
      "\n",
      "i don't know about the heart classes.  i'll look into it, but her dr (ravi)\n",
      "isn't offering up any suggestions or anything.  she saw him before the\n",
      "surgery in august, and he said things were okay.  i really don't think he's\n",
      "too helpful.\n",
      "\n",
      "she is lazy -- but it really frustrates me that she doesn't want to help\n",
      "herself.  i told her that not walking is like not taking her heart\n",
      "medication.  that didn't seem to resonate.  dad is going to go to the YMCA\n",
      "tomorrow and maybe get a membership for both of them -- they have a walking\n",
      "track there (at least it's something to do in the winter).  when she was\n",
      "down this weekend, we walked around the craft show (at the Exhibition\n",
      "place) and she said that was a lot of exercise (2 hrs).  The only problem\n",
      "is that we were just strolling, and not really walking very fast.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    John.Zufferli@\n",
      "                    enron.com            To:     Livia_Zufferli@Monitor.com\n",
      "                                         cc:\n",
      "                    11/26/2001           Subject:     RE: ali's essays\n",
      "                    01:41 PM\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "just send the essay at home\n",
      "\n",
      "I don't know what to do about mom, i don't think fear is the only thing\n",
      "holding her back , i think she is lazy\n",
      "\n",
      "is there a heart health class in Sudbury that has excercise regimines as\n",
      "well as diets?\n",
      "\n",
      "when is the last time she saw her doctor\n",
      "\n",
      "    -----Original Message-----\n",
      "   From:   Livia_Zufferli@Monitor.com@ENRON\n",
      "   Sent:   Monday, November 26, 2001 11:19 AM\n",
      "   To:     Zufferli, John\n",
      "   Subject:  ali's essays\n",
      "\n",
      "   Hi John\n",
      "\n",
      "   How was Thanksgiving?  Was the baby shower fun?\n",
      "\n",
      "   I was wondering if you'd have some time to read over Ali's Chicago\n",
      "   essays\n",
      "   later tonight?  He's going to submit them on Wednesday.  Let me know if\n",
      "   that's okay.  Do you have a printer at home?  Can I send them to your\n",
      "   home\n",
      "   account?  (I don't think Ali will be done before about 8pm or so\n",
      "   tonight).\n",
      "\n",
      "   PS:  We need to talk about mom.  I saw her this weekend -- she's gained\n",
      "   a\n",
      "   lot of weight, and hasn't been exercising at all.  Dad's pretty\n",
      "   frustrated\n",
      "   because all she does is watch tv.  I had a talk with her yesterday\n",
      "   telling\n",
      "   her that she has more risk of having a heart attack if she doesn't walk\n",
      "   /\n",
      "   exercise than if she exerts herself when exercising (i think she's\n",
      "   afraid\n",
      "   of having a heart attack while exercising).  We need to do something --\n",
      "   she's 170lbs now, and should be at around 140lbs to be healthy.\n",
      "\n",
      "   Livia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**********************************************************************\n",
      "This e-mail is the property of Enron Corp. and/or its relevant affiliate\n",
      "and may contain confidential and privileged material for the sole use of\n",
      "the intended recipient (s). Any review, use, distribution or disclosure by\n",
      "others is strictly prohibited. If you are not the intended recipient (or\n",
      "authorized to receive for the recipient), please contact the sender or\n",
      "reply to Enron Corp. at enron.messaging.administration@enron.com and delete\n",
      "all copies of the message. This e-mail (and any attachments hereto) are not\n",
      "intended to be an offer (or an acceptance) and do not create or evidence a\n",
      "binding and enforceable contract between Enron Corp. (or any of its\n",
      "affiliates) and the intended recipient or any other party, and may not be\n",
      "relied on by anyone as the basis of a contract by estoppel or otherwise.\n",
      "Thank you.\n",
      "**********************************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the last email at index 517400\n",
    "print(dataset[\"message\"][517400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d8928",
   "metadata": {},
   "source": [
    "From inspecting the first, middle, and last emails, we can see the general structure and content of the dataset.  \n",
    "\n",
    "Key observations include:\n",
    "- Emails contain extensive headers and metadata, which are not needed for text analysis.\n",
    "- Some emails may have empty subjects or body content.\n",
    "- There is inconsistent formatting, including line breaks, tabs, and spaces, which will need cleaning.\n",
    "- All emails appear to use standard ASCII encoding, but we will still check for encoding issues.\n",
    "\n",
    "These insights help us identify potential issues and guide the next steps in cleaning and parsing the dataset. Before proceeding, we will continue with data exploration to gain a better understanding of the dataset.\n",
    "\n",
    "### Descriptive Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a11f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517401, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224aaf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517401 entries, 0 to 517400\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   file     517401 non-null  object\n",
      " 1   message  517401 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d26be4",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8613c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file       0\n",
      "message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "print(dataset.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30716bd",
   "metadata": {},
   "source": [
    "### Check for Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a26bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (517401, 2)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "dataset = dataset.drop_duplicates(subset=[\"message\"]).reset_index(drop=True)\n",
    "\n",
    "# Shape of dataset after removing duplicates\n",
    "print(f\"Shape after removing duplicates: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972cc1a",
   "metadata": {},
   "source": [
    "Based on the dataset summary from `info()`, all 517,401 emails have non-null values, so there are no missing entries.  However, this does not guarantee that all emails contain meaningful content, as some messages could be completely empty.  Therefore, we perform a check to identify any emails with empty message bodies.\n",
    "\n",
    "### Check for empty emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afef5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of completely empty emails: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for completely empty emails without removing spaces for parsing\n",
    "empty_rows = dataset[dataset['message'] == \"\"]\n",
    "print(f\"Number of completely empty emails: {empty_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef67be9",
   "metadata": {},
   "source": [
    "### Check to see if there is any emails in non-ASCII Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ee406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails with non-ASCII characters: 90\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a text contains any non-ASCII characters\n",
    "def non_ascii_check(text):\n",
    "    \"\"\"\n",
    "    Check if a string contains any non-ASCII characters.\n",
    "    ASCII range = 0–127\n",
    "    \"\"\"\n",
    "    # Ensure the input is a string\n",
    "    text = str(text)\n",
    "\n",
    "    # Loop through each character in the text\n",
    "    for char in text:\n",
    "        # ord(char) gives the Unicode code point\n",
    "        if ord(char) > 127:  \n",
    "            # Found a non-ASCII character\n",
    "            return True\n",
    "\n",
    "    # If we finish the loop, all characters are ASCII\n",
    "    return False\n",
    "\n",
    "# Apply to the 'message' column\n",
    "non_ascii_rows = dataset[dataset['message'].apply(non_ascii_check)]\n",
    "print(f\"Number of emails with non-ASCII characters: {non_ascii_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d6bc5",
   "metadata": {},
   "source": [
    "\n",
    "Based on the data exploration, we observed that the dataset contains no null values, no duplicate rows, and no completely empty emails. However, we did identify a small number of emails containing non-ASCII characters. Since we are building a phishing email detection system, we have decided **not to remove these emails** and will handle them appropriately during system development. We believe this is beneficial, as these emails may help detect unusual or potentially suspicious messages while also verifying legitimate ones.  \n",
    "\n",
    "Next, we proceed to clean the dataset to prepare the emails for parsing and analysis.\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "In this section, we will clean the dataset using several methods:\n",
    "\n",
    "1. Email Parsing  \n",
    "2. Text Cleaning\n",
    "3. Post-Parsing Data Checks\n",
    "\n",
    "**Email parsing** involves extracting the meaningful content from each email, such as the body text, while removing unnecessary components like headers, metadata, or special formatting.\n",
    "\n",
    "This step is essential to prepare the emails for further cleaning, analysis, or natural language processing tasks.\n",
    "\n",
    "\n",
    "### Email Parsing\n",
    "Email parsing is essential to extract structured information from raw emails.  \n",
    "We will split this process into three main sections:\n",
    "\n",
    "1. **Header extraction:** Important fields like `Message-ID`, `Date`, `From`, `To`, `Subject`, `X-From`, and `X-To` will be extracted from the email headers.   \n",
    "2. **Message body extraction:** The main content of the email will be isolated for further analysis, including text cleaning and phishing detection. \n",
    "3. **URL extraction:** Links are crucial for identifying suspicious or malicious content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2078c16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Message-ID', '<18782981.1075855378110.JavaMail.evans@thyme>'),\n",
       " ('Date', 'Mon, 14 May 2001 16:39:00 -0700 (PDT)'),\n",
       " ('From', 'phillip.allen@enron.com'),\n",
       " ('To', 'tim.belden@enron.com'),\n",
       " ('Subject', ''),\n",
       " ('Mime-Version', '1.0'),\n",
       " ('Content-Type', 'text/plain; charset=us-ascii'),\n",
       " ('Content-Transfer-Encoding', '7bit'),\n",
       " ('X-From', 'Phillip K Allen'),\n",
       " ('X-To', 'Tim Belden <Tim Belden/Enron@EnronXGate>'),\n",
       " ('X-cc', ''),\n",
       " ('X-bcc', ''),\n",
       " ('X-Folder', \"\\\\Phillip_Allen_Jan2002_1\\\\Allen, Phillip K.\\\\'Sent Mail\"),\n",
       " ('X-Origin', 'Allen-P'),\n",
       " ('X-FileName', 'pallen (Non-Privileged).pst')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the email into correct format\n",
    "message = dataset.loc[0]['message']\n",
    "e = message_from_string(message)\n",
    "\n",
    "e.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb65cb8",
   "metadata": {},
   "source": [
    "After inspecting the content of a sample email, we observed that each email contains useful information in its headers, such as `Message-ID`, `Date`, `From`, `To`, `Subject`, and employee metadata (`X-From`, `X-To`).  \n",
    "\n",
    "To facilitate further analysis and rule-based phishing detection, we decided to extract these fields from all emails and store them in a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01f89731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing emails: 100%|██████████| 517401/517401 [00:42<00:00, 12068.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to parse email and extract specified fields\n",
    "def parse_email(raw_msg, fields=None):\n",
    "    \"\"\"\n",
    "    Parse a raw email string and extract specified header fields.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_msg : str\n",
    "        The raw email content as a string.\n",
    "    fields : list[str], optional\n",
    "        List of email fields to extract (e.g., [\"From\", \"Subject\"]).\n",
    "        If None, a default set of common fields is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping cleaned field names (lowercase, underscores)\n",
    "        to their extracted values. Missing fields return None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract fields from a raw email string\n",
    "    if fields is None:\n",
    "        fields = [\"Message-ID\", \"Date\", \"From\", \"To\", \"Subject\", \"X-From\", \"X-To\"] # Standard fields to extract if none provided\n",
    "\n",
    "    try:\n",
    "        email_obj = message_from_string(raw_msg)\n",
    "        result = {}\n",
    "\n",
    "        for field in fields:\n",
    "            # make field names easier to use in df (lowercase, underscores)\n",
    "            key = field.lower().replace(\"-\", \"_\") # X-to -> x_to\n",
    "            result[key] = email_obj.get(field) # Extract field value or None if missing\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        # if parsing fails, just fill with None\n",
    "        return {field.lower().replace(\"-\", \"_\"): None for field in fields}\n",
    "\n",
    "\n",
    "def build_email_dataframe(df, message_col=\"message\", fields=None):\n",
    "    \"\"\"\n",
    "    Parse a DataFrame column of raw email messages into structured fields.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing raw email messages.\n",
    "    message_col : str, default \"message\"\n",
    "        Name of the column in df that holds the raw email strings.\n",
    "    fields : list[str], optional\n",
    "        List of email fields to extract. If None, the default from parse_email is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame where each row corresponds to an email and each column\n",
    "        corresponds to a cleaned header field (e.g., from, subject, x_to).\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse emails in a DataFrame column into structured fields\n",
    "    parsed_rows = []\n",
    "    \n",
    "    # Loop through each raw email in the DataFrame, show a progress bar while parsing,\n",
    "    # and store the extracted fields as dictionaries in parsed_rows\n",
    "    for msg in tqdm(df[message_col], total=len(df), desc=\"Parsing emails\"):\n",
    "        parsed_rows.append(parse_email(msg, fields))\n",
    "    return pd.DataFrame(parsed_rows)\n",
    "\n",
    "# extract specified fields from all emails in the dataset\n",
    "extracted_df = build_email_dataframe(dataset, message_col=\"message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d669df4",
   "metadata": {},
   "source": [
    "#### Message Body Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fec54334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting email bodies: 100%|██████████| 517401/517401 [00:36<00:00, 14285.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the body of each email\n",
    "def body(messages):\n",
    "    # Create an empty list to store email bodies\n",
    "    column = []\n",
    "\n",
    "    # Loop through each raw email message with a progress bar\n",
    "    for message in tqdm(messages, total=len(messages), desc=\"Extracting email bodies\"):\n",
    "        # Parse the raw email string into an email object\n",
    "        e = message_from_string(message)\n",
    "\n",
    "        # Extract the body (payload) of the email\n",
    "        column.append(e.get_payload())\n",
    "\n",
    "    # Return the list of all extracted bodies\n",
    "    return column\n",
    "\n",
    "# Add a new column 'body' to the DataFrame by extracting the email body\n",
    "extracted_df['body'] = body(dataset['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67585a",
   "metadata": {},
   "source": [
    "### Validation of Body and Header Extraction  \n",
    "\n",
    "After extracting the body of each email, it is important to validate the results. Due to inconsistencies and formatting issues within the Enron dataset, some emails may not parse correctly. This can lead to:  \n",
    "\n",
    "1. **Incomplete or incorrect body extraction**  \n",
    "   - In certain cases, parts of the email headers may still remain inside the `body` field instead of being fully separated.  \n",
    "   - This requires manual or programmatic checks to confirm that the `body` column truly contains only the message content.  \n",
    "\n",
    "2. **Null or missing values in headers**  \n",
    "   - Some header fields such as `to`, `from`, or `subject` may appear as null after parsing.  \n",
    "   - These values may still exist within the raw email text but were not properly extracted during parsing.  \n",
    "\n",
    "To address this, we will:  \n",
    "- Inspect a sample of emails to verify that the `body` field contains the actual message rather than residual headers.  \n",
    "- Cross-check the raw `message` text for cases where header fields (e.g., `to`) are null, and attempt to recover these values if possible.  \n",
    "\n",
    "This step ensures that the dataset is **accurately structured** before proceeding to further cleaning and analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled x_from in 29 rows; x_to in 29 rows.\n"
     ]
    }
   ],
   "source": [
    "# Precompile regex patterns for efficiency \n",
    "XHDR_RE  = re.compile(r'^(x-from|x-to)\\s*:\\s*(.*)$', re.IGNORECASE)\n",
    "XFILE_RE = re.compile(r'(?i)^x-file(name)?\\s*:') # Match \"X-File:\" or \"X-FileName:\" (case-insensitive)\n",
    "\n",
    "# Function to extract the body of each email and recover X-From / X-To if present\n",
    "def extract_info(text):\n",
    "    \"\"\"\n",
    "    Extract the body, X-From, and X-To from an email text.\n",
    "    Steps:\n",
    "      1) Normalize and split newlines.\n",
    "      2) Recover X-From/X-To from anywhere.\n",
    "      3) Body starts after the last X-File or X-FileName line.\n",
    "      4) Remove any X-From/X-To lines from that body slice.\n",
    "    Returns:\n",
    "        (clean_body, recovered_dict)\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\", {}\n",
    "\n",
    "    # Normalize line endings\n",
    "    text = str(text).replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Recover headers from anywhere\n",
    "    recovered = {}\n",
    "    for ln in lines:\n",
    "        m = XHDR_RE.match(ln.strip())\n",
    "        if m:\n",
    "            key = m.group(1).lower().replace(\"-\", \"_\")   # \"x_from\" / \"x_to\"\n",
    "            recovered[key] = m.group(2).strip()\n",
    "\n",
    "    # Find last X-File/Name anchor (line index)\n",
    "    last_anchor = -1\n",
    "    for i, ln in enumerate(lines):\n",
    "        if XFILE_RE.match(ln.strip()):\n",
    "            last_anchor = i\n",
    "\n",
    "    # Determine the body slice\n",
    "    body_lines = lines[last_anchor + 1:] if last_anchor >= 0 else lines\n",
    "\n",
    "    # Remove any residual X-From/X-To lines from the body\n",
    "    keep = []\n",
    "    for ln in body_lines:\n",
    "        if XHDR_RE.match(ln.strip()):\n",
    "            continue\n",
    "        keep.append(ln)\n",
    "\n",
    "    # Join and trim\n",
    "    clean_body = \"\\n\".join(keep).strip()\n",
    "\n",
    "    return clean_body, recovered\n",
    "\n",
    "# Helper to check if a cell is empty (NA or whitespace)\n",
    "def is_empty(cell):\n",
    "    \"\"\"True if cell is NA or only whitespace.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return True\n",
    "    if isinstance(cell, str) and cell.strip() == \"\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to apply extraction and filling to a DataFrame\n",
    "def apply_data(df, col_body=\"body\", col_from=\"x_from\", col_to=\"x_to\"):\n",
    "    \"\"\"\n",
    "    Clean df[col_body], fill missing X-From and X-To.\n",
    "    Updates df in place and returns (filled_from, filled_to).\n",
    "    \"\"\"\n",
    "    # Ensure target columns exist\n",
    "    for col in (col_from, col_to):\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # Initialize counters and storage\n",
    "    clean_bodies = []\n",
    "    filled_from = filled_to = 0\n",
    "\n",
    "    # Process each email body\n",
    "    for i, msg in enumerate(df[col_body]):\n",
    "        # Extract cleaned body and recovered headers\n",
    "        body_clean, recovered = extract_info(msg)\n",
    "\n",
    "        # Append cleaned body\n",
    "        clean_bodies.append(body_clean)\n",
    "\n",
    "        # Use independent IFs (not elif) so both can fill\n",
    "        # Creates missing x_from/x_to columns if they don't exist\n",
    "        if \"x_from\" in recovered and is_empty(df.at[i, col_from]):\n",
    "            df.at[i, col_from] = recovered[\"x_from\"]\n",
    "            filled_from += 1\n",
    "\n",
    "        # Creates missing x_from/x_to columns if they don't exist\n",
    "        if \"x_to\" in recovered and is_empty(df.at[i, col_to]):\n",
    "            df.at[i, col_to] = recovered[\"x_to\"]\n",
    "            filled_to += 1\n",
    "\n",
    "    # Update the body column with cleaned bodies\n",
    "    df[col_body] = clean_bodies\n",
    "    return filled_from, filled_to\n",
    "\n",
    "# Run the function to clean bodies and fill missing X-From / X-To\n",
    "filled_from, filled_to = apply_data(extracted_df, col_body=\"body\", col_from=\"x_from\", col_to=\"x_to\")\n",
    "\n",
    "# Display how many rows were filled\n",
    "print(f\"Filled x_from in {filled_from} rows; x_to in {filled_to} rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53bf356",
   "metadata": {},
   "source": [
    "#### URL Extraction\n",
    "\n",
    "Next, we extract all URLs contained in the email bodies.  \n",
    "\n",
    "URLs are important for phishing detection because suspicious or malicious links are often key indicators of phishing attempts.  \n",
    "\n",
    "By isolating the URLs, we can analyze them separately and apply rules to identify potentially harmful links.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ab6e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract URLs from dataset['message'] directly\n",
    "def extract_urls_from_message(raw_msg):\n",
    "    if not isinstance(raw_msg, str):\n",
    "        return None\n",
    "    url_pattern = r'(https?://[^\\s]+)'\n",
    "    urls = re.findall(url_pattern, raw_msg)\n",
    "    return urls if urls else None\n",
    "\n",
    "# apply directly on the raw message column\n",
    "extracted_df['urls'] = dataset['message'].apply(extract_urls_from_message)\n",
    "extracted_df['num_urls'] = extracted_df['urls'].apply(lambda x: len(x) if x is not None else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b849524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>x_from</th>\n",
       "      <th>x_to</th>\n",
       "      <th>body</th>\n",
       "      <th>urls</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
       "      <td>Here is our forecast</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>Re:</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>leah.arsdall@enron.com</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      message_id  \\\n",
       "0  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    date                     from  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "\n",
       "                        to    subject           x_from  \\\n",
       "0     tim.belden@enron.com             Phillip K Allen   \n",
       "1  john.lavorato@enron.com        Re:  Phillip K Allen   \n",
       "2   leah.arsdall@enron.com   Re: test  Phillip K Allen   \n",
       "3    randall.gay@enron.com             Phillip K Allen   \n",
       "4     greg.piper@enron.com  Re: Hello  Phillip K Allen   \n",
       "\n",
       "                                                x_to  \\\n",
       "0           Tim Belden <Tim Belden/Enron@EnronXGate>   \n",
       "1  John J Lavorato <John J Lavorato/ENRON@enronXg...   \n",
       "2                                   Leah Van Arsdall   \n",
       "3                                      Randall L Gay   \n",
       "4                                         Greg Piper   \n",
       "\n",
       "                                                body  urls  num_urls  \n",
       "0                               Here is our forecast  None         0  \n",
       "1  Traveling to have a business meeting takes the...  None         0  \n",
       "2                     test successful.  way to go!!!  None         0  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  None         0  \n",
       "4                  Let's shoot for Tuesday at 11:45.  None         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows to verify extraction\n",
    "display(extracted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3218dc4",
   "metadata": {},
   "source": [
    "Based on the extracted dataset, all key headers, the email body and URLs have been successfully captured and standardized. The `body` field is readable and normalized, while `message_id` preserves its original format. Although this sample shows no URLs, the dataset is structured to capture them if present in other emails. \n",
    "\n",
    "### Text Cleaning\n",
    "\n",
    "In this step, we clean the relevant text fields in the dataset to prepare for analysis and phishing detection.  \n",
    "\n",
    "The cleaning process includes:\n",
    "1. **Removing content inside angle brackets (`<...>`)** for all columns except `message_id`.  \n",
    "   - This helps standardize email addresses and header fields.  \n",
    "2. **Normalizing whitespace**  \n",
    "   - Multiple spaces, tabs, and newlines are replaced with a single space.  \n",
    "   - Leading and trailing spaces are removed.   \n",
    "3. **Reordering and renaming columns**  \n",
    "   - Adjust column order and names to match the workflow for phishing detection analysis.  \n",
    "   - This makes the dataset more organized and easier to work with for subsequent steps.\n",
    "\n",
    "This ensures all text fields are **clean, consistent, and ready** for further processing, while preserving important information for phishing detection, including URLs, attachments, and non-ASCII characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c85780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to prevent mutation\n",
    "data_ds = extracted_df.copy()\n",
    "\n",
    "def clean_text(x, keep_tags=False):\n",
    "    \"\"\"\n",
    "    - Collapse whitespace\n",
    "    - Remove <...> entirely unless keep_tags=True\n",
    "    - Remove [] but keep the content inside\n",
    "    - Remove quotes ' and \"\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return None # No change\n",
    "\n",
    "    text = str(x)\n",
    "\n",
    "    if not keep_tags:\n",
    "        text = re.sub(r'<[^>]*>', '', text)      # remove <...>\n",
    "\n",
    "    text = re.sub(r'[\\[\\]\\'\"]+', '', text)       # drop [, ], ', \"\n",
    "\n",
    "    return re.sub(r'\\s+', ' ', text).strip()     # collapse ws + strip\n",
    "\n",
    "# now apply depending on the column \n",
    "for col in ['message_id', 'date', 'from', 'x_from', 'to', 'x_to', 'subject', 'body', 'urls', 'num_urls']:\n",
    "    if col == 'message_id':\n",
    "        data_ds[col] = data_ds[col].apply(lambda x: clean_text(x, keep_tags=True))\n",
    "    else:\n",
    "        data_ds[col] = data_ds[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "292ea6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Remove angle brackets from message_id\n",
    "# data_ds['message_id'] = data_ds['message_id'].str.replace(r'[<>]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1f1fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns for better readability\n",
    "cols = ['message_id', 'date', 'from', 'x_from', 'to', 'x_to', 'subject', 'body', 'urls', 'num_urls']\n",
    "data_ds = data_ds[cols]\n",
    "\n",
    "# Changing column names for better readability\n",
    "data_ds = data_ds.rename(columns={\n",
    "    'x_from': 'sender',\n",
    "    'x_to': 'recipient'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa62d7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>sender</th>\n",
       "      <th>to</th>\n",
       "      <th>recipient</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>urls</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "      <td>Tim Belden</td>\n",
       "      <td></td>\n",
       "      <td>Here is our forecast</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>John J Lavorato</td>\n",
       "      <td>Re:</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>leah.arsdall@enron.com</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>test successful. way to go!!!</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td></td>\n",
       "      <td>Randy, Can you send me a schedule of the salar...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>Lets shoot for Tuesday at 11:45.</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      message_id  \\\n",
       "0  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    date                     from  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "\n",
       "            sender                       to         recipient    subject  \\\n",
       "0  Phillip K Allen     tim.belden@enron.com        Tim Belden              \n",
       "1  Phillip K Allen  john.lavorato@enron.com   John J Lavorato        Re:   \n",
       "2  Phillip K Allen   leah.arsdall@enron.com  Leah Van Arsdall   Re: test   \n",
       "3  Phillip K Allen    randall.gay@enron.com     Randall L Gay              \n",
       "4  Phillip K Allen     greg.piper@enron.com        Greg Piper  Re: Hello   \n",
       "\n",
       "                                                body  urls num_urls  \n",
       "0                               Here is our forecast  None        0  \n",
       "1  Traveling to have a business meeting takes the...  None        0  \n",
       "2                      test successful. way to go!!!  None        0  \n",
       "3  Randy, Can you send me a schedule of the salar...  None        0  \n",
       "4                   Lets shoot for Tuesday at 11:45.  None        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the cleaned dataframe\n",
    "display(data_ds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05296e63",
   "metadata": {},
   "source": [
    "### Post-Parsing Data Validation\n",
    "\n",
    "After parsing and splitting the emails into separate columns, it is important to verify the integrity of the new dataset.  \n",
    "\n",
    "We will:\n",
    "\n",
    "1. **Inspect dataset summary** – Using `data.info()` to review column names, data types, and non-null counts.  \n",
    "2. **Check for null values** – Some fields such as `subject` or `body` may be empty even if the original message was not null.  \n",
    "3. **Check for duplicate rows** – Parsing may create redundant entries that should be removed.  \n",
    "\n",
    "These steps ensure that the parsed dataset is **clean, consistent, and ready** for further analysis and phishing detection.\n",
    "\n",
    "#### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab8cb102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517401 entries, 0 to 517400\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   message_id  517401 non-null  object\n",
      " 1   date        517401 non-null  object\n",
      " 2   from        517401 non-null  object\n",
      " 3   sender      517401 non-null  object\n",
      " 4   to          495554 non-null  object\n",
      " 5   recipient   517401 non-null  object\n",
      " 6   subject     517401 non-null  object\n",
      " 7   body        517401 non-null  object\n",
      " 8   urls        67121 non-null   object\n",
      " 9   num_urls    517401 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 39.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the info of cleaned dataframe\n",
    "data_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0863011",
   "metadata": {},
   "source": [
    "##### Handling of Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d948b2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message_id         0\n",
      "date               0\n",
      "from               0\n",
      "sender             0\n",
      "recipient          0\n",
      "subject            0\n",
      "body               0\n",
      "num_urls           0\n",
      "to             21847\n",
      "urls          450280\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "print(data_ds.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f69b537",
   "metadata": {},
   "source": [
    "##### Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ecabbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (517401, 10)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "data_ds = data_ds.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Shape of dataset after removing duplicates\n",
    "print(f\"Shape after removing duplicates: {data_ds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a2c94",
   "metadata": {},
   "source": [
    "# Create a label column\n",
    "Instead of assigning any label immediately, we create a new column (e.g., label) to hold the labels in the future.\n",
    "\n",
    "All entries are initialized to NaN, indicating they are currently unlabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a73a6c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>sender</th>\n",
       "      <th>to</th>\n",
       "      <th>recipient</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>urls</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "      <td>Tim Belden</td>\n",
       "      <td></td>\n",
       "      <td>Here is our forecast</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>John J Lavorato</td>\n",
       "      <td>Re:</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>leah.arsdall@enron.com</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>test successful. way to go!!!</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td></td>\n",
       "      <td>Randy, Can you send me a schedule of the salar...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>Lets shoot for Tuesday at 11:45.</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      message_id  \\\n",
       "0  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    date                     from  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  phillip.allen@enron.com   \n",
       "\n",
       "            sender                       to         recipient    subject  \\\n",
       "0  Phillip K Allen     tim.belden@enron.com        Tim Belden              \n",
       "1  Phillip K Allen  john.lavorato@enron.com   John J Lavorato        Re:   \n",
       "2  Phillip K Allen   leah.arsdall@enron.com  Leah Van Arsdall   Re: test   \n",
       "3  Phillip K Allen    randall.gay@enron.com     Randall L Gay              \n",
       "4  Phillip K Allen     greg.piper@enron.com        Greg Piper  Re: Hello   \n",
       "\n",
       "                                                body  urls num_urls  labels  \n",
       "0                               Here is our forecast  None        0     NaN  \n",
       "1  Traveling to have a business meeting takes the...  None        0     NaN  \n",
       "2                      test successful. way to go!!!  None        0     NaN  \n",
       "3  Randy, Can you send me a schedule of the salar...  None        0     NaN  \n",
       "4                   Lets shoot for Tuesday at 11:45.  None        0     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a new column 'new_col' and fill it with NaN\n",
    "data_ds['labels'] = np.nan\n",
    "\n",
    "display(data_ds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a82e20",
   "metadata": {},
   "source": [
    "# Save the cleaned dataset\n",
    "After checking for duplicates and adding the label column, the cleaned dataset is saved to a CSV file for later processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0064bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file named 'output.csv'\n",
    "data_ds.to_csv('cleaned_enron.csv', index=False) # The index=False ensures the index is not saved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
