{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283a9e73",
   "metadata": {},
   "source": [
    "# Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3f501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing of library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "from email import message_from_string\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da388c7f",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44518a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails: 4198 \n",
      "\n",
      "label\n",
      "0    2801\n",
      "1    1397\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# folder where everything is stored\n",
    "root = r\"C:\\Users\\tengt\\Downloads\\archive\"\n",
    "\n",
    "# folders for each type of email\n",
    "folders = {\n",
    "    \"spam\": os.path.join(root, r\"spam_2\\spam_2\"),\n",
    "    \"easy_ham\": os.path.join(root, r\"easy_ham\\easy_ham\"),\n",
    "    \"hard_ham\": os.path.join(root, r\"hard_ham\\hard_ham\"),\n",
    "}\n",
    "\n",
    "data = []\n",
    "\n",
    "# go through each folder\n",
    "for label, folder in folders.items():\n",
    "\n",
    "    # go through each file in the folder\n",
    "    for file in os.listdir(folder):\n",
    "\n",
    "        # full path to the file\n",
    "        path = os.path.join(folder, file)\n",
    "\n",
    "        # make sure it's a file\n",
    "        if os.path.isfile(path): \n",
    "            \n",
    "            # read the file\n",
    "            with open(path, \"r\", encoding=\"latin-1\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "\n",
    "            # spam = 1, ham = 0\n",
    "            data.append({\n",
    "                \"label\": 1 if label == \"spam\" else 0,\n",
    "                \"message\": text\n",
    "            })\n",
    "\n",
    "# put into a dataframe\n",
    "dataset = pd.DataFrame(data)\n",
    "\n",
    "# show how many emails in each class\n",
    "print(\"Total emails:\", len(dataset), \"\\n\")\n",
    "\n",
    "# print the label distribution\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69481d9",
   "metadata": {},
   "source": [
    "Note:\n",
    "- `0` → ham (normal / not spam)\n",
    "- `1` → spam (could be ads, scams, phishing, malware, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e2491d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>From amknight@mailexcite.com  Mon Jun 24 17:03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>From jordan23@mailexcite.com  Mon Jun 24 17:04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>From merchantsworld2001@juno.com  Tue Aug  6 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      1  From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...\n",
       "1      1  From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...\n",
       "2      1  From amknight@mailexcite.com  Mon Jun 24 17:03...\n",
       "3      1  From jordan23@mailexcite.com  Mon Jun 24 17:04...\n",
       "4      1  From merchantsworld2001@juno.com  Tue Aug  6 1..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1ac666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file named 'spamAssassin.csv'\n",
    "dataset.to_csv('spamAssassin.csv', index=False) # The index=False ensures the index is not saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9debd",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Exploring the dataset helps us better understand its structure and characteristics.\n",
    "\n",
    "This dataset contains a collection of **ham (legitimate) and spam emails** made available by the **Spam Assassin Project**. The dataset is widely used for email filtering research and benchmarking. It includes plain-text emails without attachments, and the messages are organized into separate folders for spam and ham.\n",
    "\n",
    "In total, the dataset contains **4,198 emails**, consisting of both spam and ham messages.\n",
    "For this section, we will follow these steps:\n",
    "\n",
    "1. Access a sample email from the dataset (first, middle, and last)  \n",
    "2. Generate descriptive statistics  \n",
    "3. Handle missing/null values  \n",
    "4. Check for duplicate rows  \n",
    "5. Check for empty emails  \n",
    "6. Check for emails containing non-ASCII characters  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293f153",
   "metadata": {},
   "source": [
    "### Accessing Sample Emails from the Dataset (First, Middle, and Last)\n",
    "\n",
    "The dataset contains 4198 rows (indexed 0 to 4197).  \n",
    "We will examine the first, middle, and last emails to inspect their structure and determine the cleaning steps required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5a832bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ilug-admin@linux.ie  Tue Aug  6 11:51:02 2002\n",
      "Return-Path: <ilug-admin@linux.ie>\n",
      "Delivered-To: yyyy@localhost.netnoteinc.com\n",
      "Received: from localhost (localhost [127.0.0.1])\n",
      "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\n",
      "\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)\n",
      "Received: from phobos [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)\n",
      "Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for\n",
      "    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100\n",
      "Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org\n",
      "    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100\n",
      "Received: from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net\n",
      "    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for\n",
      "    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100\n",
      "X-Authentication-Warning: lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net\n",
      "    [64.0.57.142] claimed to be bettyjagessar.com\n",
      "Received: from 64.0.57.142 [202.63.165.34] by bettyjagessar.com\n",
      "    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400\n",
      "Message-Id: <1028311679.886@0.57.142>\n",
      "Date: Fri, 02 Aug 2002 23:37:59 0530\n",
      "To: ilug@linux.ie\n",
      "From: \"Start Now\" <startnow2002@hotmail.com>\n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/plain; charset=\"US-ASCII\"; format=flowed\n",
      "Subject: [ILUG] STOP THE MLM INSANITY\n",
      "Sender: ilug-admin@linux.ie\n",
      "Errors-To: ilug-admin@linux.ie\n",
      "X-Mailman-Version: 1.1\n",
      "Precedence: bulk\n",
      "List-Id: Irish Linux Users' Group <ilug.linux.ie>\n",
      "X-Beenthere: ilug@linux.ie\n",
      "\n",
      "Greetings!\n",
      "\n",
      "You are receiving this letter because you have expressed an interest in \n",
      "receiving information about online business opportunities. If this is \n",
      "erroneous then please accept my most sincere apology. This is a one-time \n",
      "mailing, so no removal is necessary.\n",
      "\n",
      "If you've been burned, betrayed, and back-stabbed by multi-level marketing, \n",
      "MLM, then please read this letter. It could be the most important one that \n",
      "has ever landed in your Inbox.\n",
      "\n",
      "MULTI-LEVEL MARKETING IS A HUGE MISTAKE FOR MOST PEOPLE\n",
      "\n",
      "MLM has failed to deliver on its promises for the past 50 years. The pursuit \n",
      "of the \"MLM Dream\" has cost hundreds of thousands of people their friends, \n",
      "their fortunes and their sacred honor. The fact is that MLM is fatally \n",
      "flawed, meaning that it CANNOT work for most people.\n",
      "\n",
      "The companies and the few who earn the big money in MLM are NOT going to \n",
      "tell you the real story. FINALLY, there is someone who has the courage to \n",
      "cut through the hype and lies and tell the TRUTH about MLM.\n",
      "\n",
      "HERE'S GOOD NEWS\n",
      "\n",
      "There IS an alternative to MLM that WORKS, and works BIG! If you haven't yet \n",
      "abandoned your dreams, then you need to see this. Earning the kind of income \n",
      "you've dreamed about is easier than you think!\n",
      "\n",
      "With your permission, I'd like to send you a brief letter that will tell you \n",
      "WHY MLM doesn't work for most people and will then introduce you to \n",
      "something so new and refreshing that you'll wonder why you haven't heard of \n",
      "this before.\n",
      "\n",
      "I promise that there will be NO unwanted follow up, NO sales pitch, no one \n",
      "will call you, and your email address will only be used to send you the \n",
      "information. Period.\n",
      "\n",
      "To receive this free, life-changing information, simply click Reply, type \n",
      "\"Send Info\" in the Subject box and hit Send. I'll get the information to you \n",
      "within 24 hours. Just look for the words MLM WALL OF SHAME in your Inbox.\n",
      "\n",
      "Cordially,\n",
      "\n",
      "Siddhi\n",
      "\n",
      "P.S. Someone recently sent the letter to me and it has been the most \n",
      "eye-opening, financially beneficial information I have ever received. I \n",
      "honestly believe that you will feel the same way once you've read it. And \n",
      "it's FREE!\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "This email is NEVER sent unsolicited.  THIS IS NOT \"SPAM\". You are receiving \n",
      "this email because you EXPLICITLY signed yourself up to our list with our \n",
      "online signup form or through use of our FFA Links Page and E-MailDOM \n",
      "systems, which have EXPLICIT terms of use which state that through its use \n",
      "you agree to receive our emailings.  You may also be a member of a Altra \n",
      "Computer Systems list or one of many numerous FREE Marketing Services and as \n",
      "such you agreed when you signed up for such list that you would also be \n",
      "receiving this emailing.\n",
      "Due to the above, this email message cannot be considered unsolicitated, or \n",
      "spam.\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-- \n",
      "Irish Linux Users' Group: ilug@linux.ie\n",
      "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
      "List maintainer: listmaster@linux.ie\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the first email at index 0\n",
    "print(dataset[\"message\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4cb02dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From fork-admin@xent.com  Thu Sep 19 13:14:49 2002\n",
      "Return-Path: <fork-admin@xent.com>\n",
      "Delivered-To: yyyy@localhost.example.com\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id E6F3016F03\n",
      "\tfor <jm@localhost>; Thu, 19 Sep 2002 13:14:47 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Thu, 19 Sep 2002 13:14:47 +0100 (IST)\n",
      "Received: from xent.com ([64.161.22.236]) by dogma.slashnull.org\n",
      "    (8.11.6/8.11.6) with ESMTP id g8JC7hC18737 for <jm@jmason.org>;\n",
      "    Thu, 19 Sep 2002 13:07:43 +0100\n",
      "Received: from lair.xent.com (localhost [127.0.0.1]) by xent.com (Postfix)\n",
      "    with ESMTP id 2E69B2940FC; Thu, 19 Sep 2002 05:04:06 -0700 (PDT)\n",
      "Delivered-To: fork@example.com\n",
      "Received: from sunserver.permafrost.net (u172n16.hfx.eastlink.ca\n",
      "    [24.222.172.16]) by xent.com (Postfix) with ESMTP id 4BE5029409E for\n",
      "    <fork@xent.com>; Thu, 19 Sep 2002 05:03:15 -0700 (PDT)\n",
      "Received: from [192.168.123.179] (helo=permafrost.net) by\n",
      "    sunserver.permafrost.net with esmtp (Exim 3.35 #1 (Debian)) id\n",
      "    17s01y-00081V-00; Thu, 19 Sep 2002 09:03:38 -0300\n",
      "Message-Id: <3D89BEA8.4010107@permafrost.net>\n",
      "From: Owen Byrne <owen@permafrost.net>\n",
      "User-Agent: Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.1) Gecko/20020826\n",
      "X-Accept-Language: en-us, en\n",
      "MIME-Version: 1.0\n",
      "To: Chuck Murcko <chuck@topsail.org>\n",
      "Cc: fork@example.com\n",
      "Subject: Re: Hanson's Sept 11 message in the National Review\n",
      "References: <2404C790-CBC5-11D6-9930-003065F93D3A@topsail.org>\n",
      "Content-Type: text/plain; charset=us-ascii; format=flowed\n",
      "Content-Transfer-Encoding: 7bit\n",
      "Sender: fork-admin@xent.com\n",
      "Errors-To: fork-admin@xent.com\n",
      "X-Beenthere: fork@example.com\n",
      "X-Mailman-Version: 2.0.11\n",
      "Precedence: bulk\n",
      "List-Help: <mailto:fork-request@xent.com?subject=help>\n",
      "List-Post: <mailto:fork@example.com>\n",
      "List-Subscribe: <http://xent.com/mailman/listinfo/fork>, <mailto:fork-request@xent.com?subject=subscribe>\n",
      "List-Id: Friends of Rohit Khare <fork.xent.com>\n",
      "List-Unsubscribe: <http://xent.com/mailman/listinfo/fork>,\n",
      "    <mailto:fork-request@xent.com?subject=unsubscribe>\n",
      "List-Archive: <http://xent.com/pipermail/fork/>\n",
      "Date: Thu, 19 Sep 2002 09:10:16 -0300\n",
      "X-Spam-Status: No, hits=-5.8 required=5.0\n",
      "\ttests=AWL,EMAIL_ATTRIBUTION,KNOWN_MAILING_LIST,QUOTED_EMAIL_TEXT,\n",
      "\t      REFERENCES,REPLY_WITH_QUOTES,USER_AGENT,\n",
      "\t      USER_AGENT_MOZILLA_UA,X_ACCEPT_LANG\n",
      "\tversion=2.50-cvs\n",
      "X-Spam-Level: \n",
      "\n",
      "Chuck Murcko wrote:\n",
      "\n",
      "> Heh, ten years ago saying the exact same words was most definitely not \n",
      "> \"parroting the party line\".\n",
      ">\n",
      "> It was even less so thirty years ago. My story remains the same, take \n",
      "> it or leave it. I've said the same words to white supremacists as to \n",
      "> suburban leftist punks as to homeys as to French Irish, etc. etc.:\n",
      ">\n",
      "> I don't have to agree with anything you say. I *am* obligated to \n",
      "> defend to the death your right to say it. I don't give a rat's ass \n",
      "> where you say it, even in France. I don't care where the political \n",
      "> pendulum has swung currently.\n",
      ">\n",
      "> Chuck\n",
      "\n",
      "\n",
      "I had to laugh at Rumsfield yesterday - when he was heckled by \n",
      "protestors, he said something like \"They couldn't do that in Iraq.\" \n",
      "Meanwhile, from what I could tell, the protestors were being arrested.\n",
      "\n",
      "Owen\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the middle email at index 258700\n",
    "print(dataset[\"message\"][2098])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ee730a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path: <test-admin@lists.sourceforge.net>\n",
      "Received: from usw-sf-list2.sourceforge.net (usw-sf-fw2.sourceforge.net\n",
      "\t[216.136.171.252]) by home.sewingwitch.com (8.11.6/8.11.6) with ESMTP id\n",
      "\tg9208B729827 for <shiva+qpopper-webdev@sewingwitch.com>; Tue, 1 Oct 2002\n",
      "\t17:08:11 -0700\n",
      "Received: from usw-sf-list1-b.sourceforge.net ([10.3.1.13]\n",
      "\thelo=usw-sf-list1.sourceforge.net) by usw-sf-list2.sourceforge.net with\n",
      "\tesmtp (Exim 3.31-VA-mm2 #1 (Debian)) id 17wX3l-0004o7-00 for\n",
      "\t<shiva+qpopper-webdev@sewingwitch.com>; Tue, 01 Oct 2002 17:08:13 -0700\n",
      "Date: Tue, 01 Oct 2002 17:08:10 -0700\n",
      "Subject: (SPAM? 08.00) lists.sourceforge.net mailing list memberships reminder\n",
      "From: mailman-owner@lists.sourceforge.net\n",
      "To: shiva+qpopper-webdev@sewingwitch.com\n",
      "X-No-Archive: yes\n",
      "X-Ack: no\n",
      "Sender: test-admin@lists.sourceforge.net\n",
      "Errors-To: test-admin@lists.sourceforge.net\n",
      "X-BeenThere: test@lists.sourceforge.net\n",
      "X-Mailman-Version: 2.0.9-sf.net\n",
      "Precedence: bulk\n",
      "Message-Id: <E17wX3l-0004o7-00@usw-sf-list2.sourceforge.net>\n",
      "Content-Type: text/plain; CHARSET=US-ASCII\n",
      "X-Evolution-Source: imap://ken@home.sewingwitch.com/\n",
      "Mime-Version: 1.0\n",
      "Content-Transfer-Encoding: 7bit\n",
      "\n",
      "******************************************************************************* \n",
      "\n",
      "\n",
      "This is an official mailing from SourceForge.net.  You are receiving\n",
      "this message because you had previously subscribed to one of the more\n",
      "than 20,000 opt-in mailing lists managed by SourceForge.net for the\n",
      "projects hosted on SourceForge.net.  This message is a monthly\n",
      "subscription reminder, automatically generated by the Mailman mailing\n",
      "list management software used by SourceForge.net\n",
      "(http://www.list.org).\n",
      "\n",
      "DO NOT REPLY to this email; instructions are provided here for\n",
      "unsubscribing from a list, and for obtaining support.  Support is not\n",
      "provided by email.\n",
      "\n",
      "To UNSUBSCRIBE:\n",
      " 1. Use your web browser to access the list management URL for the\n",
      "    list you wish to unsubscribe from (the list management URL for\n",
      "each\n",
      "    list may be found at the bottom of this email).\n",
      " 2. If you do not already know your list management password, click on\n",
      "the\n",
      "    'Email My Password To Me' button.  List passwords will differ from\n",
      "    list-to-list, and are different from the password you use on the\n",
      "    SourceForge.net site, if you have an account there.\n",
      " 3. From the list management page, enter your list password (see step\n",
      "#2,\n",
      "    above, if you do not know your list password) in to the\n",
      "    'Unsubscribing from...' box, found in the upper right-hand corner\n",
      "of\n",
      "    the list management page.\n",
      " 4. After entering the password for your subscription and clicking on\n",
      "the\n",
      "    'Unsubscribe' button, you will be unsubscribed from the list\n",
      "immediately.\n",
      " 5. To unsubscribe from more than one list, you must access the\n",
      "management\n",
      "    page for each, using the appropriate URL, listed at the bottom of\n",
      "this\n",
      "    email.\n",
      "\n",
      "To contact SUPPORT staff:\n",
      " 1. All mailing lists hosted by SourceForge.net are opt-in via a\n",
      "three-way\n",
      "    handshake.  This is not a spam list; subscription to this list\n",
      "    required you to respond to a confirmation email that was sent to\n",
      "your\n",
      "    email address.\n",
      " 2. SourceForge.net provides hosting for more than 20,000 different\n",
      "    mailing lists; if you contact our support staff, you must provide\n",
      "    A) the email address associated with this monthly mailing AND\n",
      "    B) the list of mailing lists from the bottom of this mailing\n",
      "    Without this information, it will be difficult to assist you.\n",
      " 3. Support is not provided by email.  All support inquiries related\n",
      "to\n",
      "    this mailing should be submitted as a Support Request at this URL:\n",
      "    https://sourceforge.net/tracker/?func=add&group_id=1&atid=200001\n",
      "    Proper issue reporting will help us to respond quickly.\n",
      "\n",
      "To change your subscription settings:\n",
      " 1. Make use of the list management URL and password for the list\n",
      "    in question; from the list management page, you may change your\n",
      "    password or subscription preferences.\n",
      " 2. If you do not already know your list management password, click on\n",
      "the\n",
      "    'Email My Password To Me' button.  List passwords will differ from\n",
      "    list-to-list, and are different from the password you use on the\n",
      "    SourceForge.net site, if you have an account there.\n",
      "\n",
      "If your email address is changing:\n",
      " 1. Access the URL provided for list management at the bottom of this\n",
      "email.\n",
      " 2. Click on the name of the list, located at the bottom of the list\n",
      "    management page (the link preceding the email address for the list\n",
      "admin).\n",
      " 3. Follow the instructions in the 'Subscribing to...' section to\n",
      "subscribe\n",
      "    your NEW email address to the list.\n",
      " 4. Once subscribed, follow the instructions in the UNSUBSCRIBE\n",
      "section\n",
      "    (above) to unsubscribe the old address from the list in question.\n",
      " NOTE: There is no means to change the email address on your\n",
      "subscriptions\n",
      " directly; use this procedure to change the subscriptions for each of\n",
      "the\n",
      " lists you subscribe to.\n",
      "\n",
      "If you are a list ADMINISTRATOR and have lost your list admin\n",
      "password:\n",
      " 1. Follow the instructions in the SUPPORT section of this message\n",
      "(above)\n",
      "    to request a reset of your list admin password.  Please include a\n",
      "list\n",
      "    of the mailing lists whose passwords you need reset.  No automated\n",
      "    facility is provided to reset list admin passwords.\n",
      "\n",
      "Please note: As of 2002-08-20, this mailing will no longer include the\n",
      "list management passwords for your subscriptions.  If you have lost\n",
      "your list management password, you will need to recover those\n",
      "passwords on a per-list basis as described in #2 of the UNSUBSCRIBE\n",
      "section, above.\n",
      "\n",
      "If you encounter a problem in accessing the mailing list management\n",
      "page for a list, please contact the SourceForge.net team (see our\n",
      "SUPPORT instructions, above) for assistance AFTER you try using a\n",
      "different web browser for accessing that page.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "the SourceForge.net team\n",
      "\n",
      "\n",
      "(mailing list management URLs follow)\n",
      "*******************************************************************************\n",
      "\n",
      "\n",
      "This is a reminder, sent out once a month, about your\n",
      "lists.sourceforge.net mailing list memberships.  It includes your\n",
      "subscription info and how to use it to change it or unsubscribe from a\n",
      "list.\n",
      "\n",
      "You can visit the URLs to change your membership status or\n",
      "configuration, including unsubscribing, setting digest-style delivery\n",
      "or disabling delivery altogether (e.g., for a vacation), and so on.\n",
      "\n",
      "In addition to the URL interfaces, you can also use email to make such\n",
      "changes.  For more info, send a message to the '-request' address of\n",
      "the list (for example, qpopper-webdev-request@lists.sourceforge.net)\n",
      "containing just the word 'help' in the message body, and an email\n",
      "message will be sent to you with instructions.\n",
      "\n",
      "If you have questions, problems, comments, etc, send them to\n",
      "mailman-owner@lists.sourceforge.net.  Thanks!\n",
      "\n",
      "Subscriptions for shiva+qpopper-webdev@sewingwitch.com:\n",
      "\n",
      "List                                     // URL    \n",
      "----                                     --------  \n",
      "qpopper-webdev@lists.sourceforge.net    \n",
      "https://lists.sourceforge.net/lists/options/qpopper-webdev/shiva%2Bqpopper-webdev%40sewingwitch.com\n"
     ]
    }
   ],
   "source": [
    "# Accessing the content of the last email at index 517400\n",
    "print(dataset[\"message\"][4197])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f386b7",
   "metadata": {},
   "source": [
    "From inspecting the first, middle, and last emails, we can see the general structure and content of the dataset.  \n",
    "\n",
    "Key observations include:\n",
    "- Emails contain extensive headers and metadata, which are not needed for text analysis.\n",
    "- There is inconsistent formatting, including line breaks, tabs, and spaces, which will need cleaning.\n",
    "- All emails appear to use standard ASCII encoding, but we will still check for encoding issues.\n",
    "\n",
    "These insights help us identify potential issues and guide the next steps in cleaning and parsing the dataset. Before proceeding, we will continue with data exploration to gain a better understanding of the dataset.\n",
    "\n",
    "### Descriptive Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4b0bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4198 entries, 0 to 4197\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    4198 non-null   int64 \n",
      " 1   message  4198 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 65.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Make a copy to prevent mutation\n",
    "data_ds = dataset.copy()\n",
    "\n",
    "# Descriptive statistics\n",
    "print(data_ds.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77c53d",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40e4e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label      0\n",
      "message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "print(data_ds.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70434ba5",
   "metadata": {},
   "source": [
    "### Check for Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "001a0183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing duplicates: (4198, 2)\n",
      "Shape after removing duplicates: (4178, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shape of data_ds before removing duplicates\n",
    "print(f\"Shape before removing duplicates: {data_ds.shape}\")\n",
    "\n",
    "# Removing duplicate rows\n",
    "data_ds = data_ds.drop_duplicates(subset=[\"message\"]).reset_index(drop=True)\n",
    "\n",
    "# Shape of data_ds after removing duplicates\n",
    "print(f\"Shape after removing duplicates: {data_ds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d03636",
   "metadata": {},
   "source": [
    "Based on the dataset summary from `info()`, all 4178 emails have non-null values in the `message` column, so there are no missing entries. However, this does not guarantee that all emails contain meaningful content, as some messages body could still be empty. Therefore, we performed a check to identify any emails with empty message bodies.\n",
    "\n",
    "In addition, 20 duplicate emails (based on the `message` column) were removed, resulting in a cleaner dataset.\n",
    "\n",
    "### Check for empty emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "098019a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of completely empty emails: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for completely empty emails without removing spaces for parsing\n",
    "empty_rows = data_ds[data_ds['message'] == \"\"]\n",
    "print(f\"Number of completely empty emails: {empty_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a441f",
   "metadata": {},
   "source": [
    "### Check to see if there is any emails in non-ASCII Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2bef3e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails with non-ASCII characters: 294\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a text contains any non-ASCII characters\n",
    "def non_ascii_check(text):\n",
    "    \"\"\"\n",
    "    Check if a string contains any non-ASCII characters.\n",
    "    ASCII range = 0–127\n",
    "    \"\"\"\n",
    "    # Ensure the input is a string\n",
    "    text = str(text)\n",
    "\n",
    "    # Loop through each character in the text\n",
    "    for char in text:\n",
    "        # ord(char) gives the Unicode code point\n",
    "        if ord(char) > 127:  \n",
    "            # Found a non-ASCII character\n",
    "            return True\n",
    "\n",
    "    # If we finish the loop, all characters are ASCII\n",
    "    return False\n",
    "\n",
    "# Apply to the 'message' column\n",
    "non_ascii_rows = dataset[dataset['message'].apply(non_ascii_check)]\n",
    "print(f\"Number of emails with non-ASCII characters: {non_ascii_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc156d",
   "metadata": {},
   "source": [
    "Based on the data exploration, we observed that the Spam Assassin dataset contains no null values in the `message` column, no completely empty emails, and 20 duplicate rows were found. After this cleaning, the dataset consists of 4178 unique emails. We also identified a small number of emails containing non-ASCII characters. Since we are building a phishing email detection system, we have decided **not to remove these emails** and will handle them appropriately during system development. This is beneficial, as such emails may help detect unusual or suspicious patterns while also verifying legitimate cases.  \n",
    "\n",
    "Next, we proceed to clean the dataset to prepare the emails for parsing and analysis.\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "In this section, we will clean the dataset using several methods:\n",
    "\n",
    "1. Email Parsing  \n",
    "2. Text Cleaning  \n",
    "3. Post-Parsing Data Checks  \n",
    "\n",
    "**Email parsing** involves extracting the meaningful content from each email, such as the body text, while removing unnecessary components like headers, metadata, or special formatting. This step is essential to prepare the emails for further cleaning, analysis, or natural language processing tasks.\n",
    "\n",
    "### Email Parsing\n",
    "Email parsing is essential to extract structured information from raw emails.  \n",
    "We will split this process into three main sections:\n",
    "\n",
    "1. **Header extraction:** Important fields like `Message-ID`, `Date`, `From`, `To`, `Subject`, etc will be extracted from the email headers.  \n",
    "2. **Message body extraction:** The main content of the email will be isolated for further analysis, including text cleaning and phishing detection.  \n",
    "3. **URL extraction:** Links are crucial for identifying suspicious or malicious content.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a018339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Return-Path', '<ilug-admin@linux.ie>'),\n",
       " ('Delivered-To', 'yyyy@localhost.netnoteinc.com'),\n",
       " ('Received',\n",
       "  'from localhost (localhost [127.0.0.1])\\n\\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\\n\\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)'),\n",
       " ('Received',\n",
       "  'from phobos [127.0.0.1]\\n\\tby localhost with IMAP (fetchmail-5.9.0)\\n\\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)'),\n",
       " ('Received',\n",
       "  'from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by\\n    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for\\n    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100'),\n",
       " ('Received',\n",
       "  'from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org\\n    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100'),\n",
       " ('Received',\n",
       "  'from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net\\n    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for\\n    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100'),\n",
       " ('X-Authentication-Warning',\n",
       "  'lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net\\n    [64.0.57.142] claimed to be bettyjagessar.com'),\n",
       " ('Received',\n",
       "  'from 64.0.57.142 [202.63.165.34] by bettyjagessar.com\\n    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400'),\n",
       " ('Message-Id', '<1028311679.886@0.57.142>'),\n",
       " ('Date', 'Fri, 02 Aug 2002 23:37:59 0530'),\n",
       " ('To', 'ilug@linux.ie'),\n",
       " ('From', '\"Start Now\" <startnow2002@hotmail.com>'),\n",
       " ('MIME-Version', '1.0'),\n",
       " ('Content-Type', 'text/plain; charset=\"US-ASCII\"; format=flowed'),\n",
       " ('Subject', '[ILUG] STOP THE MLM INSANITY'),\n",
       " ('Sender', 'ilug-admin@linux.ie'),\n",
       " ('Errors-To', 'ilug-admin@linux.ie'),\n",
       " ('X-Mailman-Version', '1.1'),\n",
       " ('Precedence', 'bulk'),\n",
       " ('List-Id', \"Irish Linux Users' Group <ilug.linux.ie>\"),\n",
       " ('X-Beenthere', 'ilug@linux.ie')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the email into correct format\n",
    "message = dataset.loc[0]['message']\n",
    "e = message_from_string(message)\n",
    "\n",
    "e.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842cb99",
   "metadata": {},
   "source": [
    "After examining a sample email, we found that the headers contain valuable information, including `Message-ID`, `Date`, `From`, `To`, `Subject`, and other relevant metadata such as `Sender`, `Return-Path`, and mailing list information (`List-Id`).  \n",
    "\n",
    "To support further analysis and enable rule-based phishing detection, we extracted these fields from all emails and organized them into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "937ef3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing emails: 100%|██████████| 4178/4178 [00:00<00:00, 7575.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to parse email and extract specified fields\n",
    "def parse_email(raw_msg, fields=None):\n",
    "    \"\"\"\n",
    "    Parse a raw email string and extract specified header fields.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_msg : str\n",
    "        The raw email content as a string.\n",
    "    fields : list[str], optional\n",
    "        List of email fields to extract (e.g., [\"From\", \"Subject\"]).\n",
    "        If None, a default set of common fields is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping cleaned field names (lowercase, underscores)\n",
    "        to their extracted values. Missing fields return None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract fields from a raw email string\n",
    "    if fields is None:\n",
    "        fields = [\"Message-ID\", \"Date\", \"From\", \"To\", \"Subject\", \"Sender\", \"List-Id\"] # Standard fields to extract if none provided\n",
    "\n",
    "    try:\n",
    "        email_obj = message_from_string(raw_msg)\n",
    "        result = {}\n",
    "\n",
    "        for field in fields:\n",
    "            # make field names easier to use in df (lowercase, underscores)\n",
    "            key = field.lower().replace(\"-\", \"_\") # X-to -> x_to\n",
    "            result[key] = email_obj.get(field) # Extract field value or None if missing\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        # if parsing fails, just fill with None\n",
    "        return {field.lower().replace(\"-\", \"_\"): None for field in fields}\n",
    "\n",
    "\n",
    "def build_email_dataframe(df, message_col=\"message\", fields=None):\n",
    "    \"\"\"\n",
    "    Parse a DataFrame column of raw email messages into structured fields.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing raw email messages.\n",
    "    message_col : str, default \"message\"\n",
    "        Name of the column in df that holds the raw email strings.\n",
    "    fields : list[str], optional\n",
    "        List of email fields to extract. If None, the default from parse_email is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame where each row corresponds to an email and each column\n",
    "        corresponds to a cleaned header field (e.g., from, subject, x_to).\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse emails in a DataFrame column into structured fields\n",
    "    parsed_rows = []\n",
    "    \n",
    "    # Loop through each raw email in the DataFrame, show a progress bar while parsing,\n",
    "    # and store the extracted fields as dictionaries in parsed_rows\n",
    "    for msg in tqdm(df[message_col], total=len(df), desc=\"Parsing emails\"):\n",
    "        parsed_rows.append(parse_email(msg, fields))\n",
    "    \n",
    "    # Form a DataFrame from the list of parsed email dictionaries\n",
    "    parsed_df = pd.DataFrame(parsed_rows, index=df.index)  # keep same index\n",
    "\n",
    "    # Return the df with original and parsed fields\n",
    "    return pd.concat([df, parsed_df], axis=1)  # merge with original\n",
    "\n",
    "# extract specified fields from all emails in the dataset\n",
    "extracted_df = build_email_dataframe(data_ds, message_col=\"message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd4dcb",
   "metadata": {},
   "source": [
    "#### Message Body Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6420a8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting email bodies: 100%|██████████| 4178/4178 [00:00<00:00, 6601.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the body of each email\n",
    "def body(messages):\n",
    "    # Create an empty list to store email bodies\n",
    "    column = []\n",
    "\n",
    "    # Loop through each raw email message with a progress bar\n",
    "    for message in tqdm(messages, total=len(messages), desc=\"Extracting email bodies\"):\n",
    "        # Parse the raw email string into an email object\n",
    "        e = message_from_string(message)\n",
    "\n",
    "        # Extract the body (payload) of the email\n",
    "        column.append(e.get_payload())\n",
    "\n",
    "    # Return the list of all extracted bodies\n",
    "    return column\n",
    "\n",
    "# Add a new column 'body' to the DataFrame by extracting the email body\n",
    "extracted_df['body'] = body(data_ds['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "58da8248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>list_id</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...</td>\n",
       "      <td>&lt;1028311679.886@0.57.142&gt;</td>\n",
       "      <td>Fri, 02 Aug 2002 23:37:59 0530</td>\n",
       "      <td>\"Start Now\" &lt;startnow2002@hotmail.com&gt;</td>\n",
       "      <td>ilug@linux.ie</td>\n",
       "      <td>[ILUG] STOP THE MLM INSANITY</td>\n",
       "      <td>ilug-admin@linux.ie</td>\n",
       "      <td>Irish Linux Users' Group &lt;ilug.linux.ie&gt;</td>\n",
       "      <td>Greetings!\\n\\nYou are receiving this letter be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...</td>\n",
       "      <td>&lt;B0000178595@203.129.205.5.205.129.203.in-addr...</td>\n",
       "      <td>Mon, 28 Jul 1980 14:01:35</td>\n",
       "      <td>lmrn@mailexcite.com</td>\n",
       "      <td>ranmoore@cybertime.net</td>\n",
       "      <td>Real Protection, Stun Guns!  Free Shipping! Ti...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;html&gt;\\n&lt;body&gt;\\n&lt;center&gt;\\n&lt;h3&gt;\\n&lt;font color=\"b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>From amknight@mailexcite.com  Mon Jun 24 17:03...</td>\n",
       "      <td>&lt;0845b5355070f52WEBCUST2@webcust2.hightowertec...</td>\n",
       "      <td>Wed, 30 Jul 1980 18:25:49</td>\n",
       "      <td>amknight@mailexcite.com</td>\n",
       "      <td>cbmark@cbmark.com</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;html&gt;\\n&lt;body&gt;\\n&lt;center&gt;\\n&lt;b&gt;\\n&lt;font color=\"bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>From jordan23@mailexcite.com  Mon Jun 24 17:04...</td>\n",
       "      <td>&lt;0925c5750200f52WEBCUST2@webcust2.hightowertec...</td>\n",
       "      <td>Thu, 31 Jul 1980 07:20:54</td>\n",
       "      <td>jordan23@mailexcite.com</td>\n",
       "      <td>ranmoore@swbell.net</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;html&gt;\\n&lt;body&gt;\\n&lt;center&gt;\\n&lt;b&gt;\\n&lt;font color=\"bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>From merchantsworld2001@juno.com  Tue Aug  6 1...</td>\n",
       "      <td>&lt;200208040037.BAA09623@webnote.net&gt;</td>\n",
       "      <td>Sun, 19 Oct 1980 10:55:16</td>\n",
       "      <td>yyyy@pluriproj.pt</td>\n",
       "      <td>yyyy@pluriproj.pt</td>\n",
       "      <td>Never Repay Cash Grants, $500 - $50,000, Secre...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;html&gt;&lt;xbody&gt;\\n&lt;hr width = \"100%\"&gt;\\n&lt;center&gt;&lt;h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      1  From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...   \n",
       "1      1  From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...   \n",
       "2      1  From amknight@mailexcite.com  Mon Jun 24 17:03...   \n",
       "3      1  From jordan23@mailexcite.com  Mon Jun 24 17:04...   \n",
       "4      1  From merchantsworld2001@juno.com  Tue Aug  6 1...   \n",
       "\n",
       "                                          message_id  \\\n",
       "0                          <1028311679.886@0.57.142>   \n",
       "1  <B0000178595@203.129.205.5.205.129.203.in-addr...   \n",
       "2  <0845b5355070f52WEBCUST2@webcust2.hightowertec...   \n",
       "3  <0925c5750200f52WEBCUST2@webcust2.hightowertec...   \n",
       "4                <200208040037.BAA09623@webnote.net>   \n",
       "\n",
       "                             date                                    from  \\\n",
       "0  Fri, 02 Aug 2002 23:37:59 0530  \"Start Now\" <startnow2002@hotmail.com>   \n",
       "1       Mon, 28 Jul 1980 14:01:35                     lmrn@mailexcite.com   \n",
       "2       Wed, 30 Jul 1980 18:25:49                 amknight@mailexcite.com   \n",
       "3       Thu, 31 Jul 1980 07:20:54                 jordan23@mailexcite.com   \n",
       "4       Sun, 19 Oct 1980 10:55:16                       yyyy@pluriproj.pt   \n",
       "\n",
       "                       to                                            subject  \\\n",
       "0           ilug@linux.ie                       [ILUG] STOP THE MLM INSANITY   \n",
       "1  ranmoore@cybertime.net  Real Protection, Stun Guns!  Free Shipping! Ti...   \n",
       "2       cbmark@cbmark.com  New Improved Fat Burners, Now With TV Fat Abso...   \n",
       "3     ranmoore@swbell.net  New Improved Fat Burners, Now With TV Fat Abso...   \n",
       "4       yyyy@pluriproj.pt  Never Repay Cash Grants, $500 - $50,000, Secre...   \n",
       "\n",
       "                sender                                   list_id  \\\n",
       "0  ilug-admin@linux.ie  Irish Linux Users' Group <ilug.linux.ie>   \n",
       "1                 None                                      None   \n",
       "2                 None                                      None   \n",
       "3                 None                                      None   \n",
       "4                 None                                      None   \n",
       "\n",
       "                                                body  \n",
       "0  Greetings!\\n\\nYou are receiving this letter be...  \n",
       "1  <html>\\n<body>\\n<center>\\n<h3>\\n<font color=\"b...  \n",
       "2  <html>\\n<body>\\n<center>\\n<b>\\n<font color=\"bl...  \n",
       "3  <html>\\n<body>\\n<center>\\n<b>\\n<font color=\"bl...  \n",
       "4  <html><xbody>\\n<hr width = \"100%\">\\n<center><h...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of the new dataframe with extracted fields\n",
    "display(extracted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fce0e",
   "metadata": {},
   "source": [
    "### Validation of Body and Header Extraction  \n",
    "\n",
    "After extracting the body of each email, it is important to validate the results. This is because, we want to check if there is any formatting issues within the dataset, we are unknown of. As this may caused some of the emails to not be parse correctly. As a results, leading to:  \n",
    "\n",
    "1. **Incomplete or incorrect body extraction**  \n",
    "   - In certain cases, parts of the email headers may still remain inside the `body` field instead of being fully separated.  \n",
    "   - This requires manual or programmatic checks to confirm that the `body` column truly contains only the message content.  \n",
    "\n",
    "2. **Null or missing values in other headers fields**  \n",
    "   - Some header fields such as `to`, `from`, or `subject` may appear as null after parsing.  \n",
    "   - These values may still exist within the raw email text but were not properly extracted during parsing.  \n",
    "\n",
    "To address this, we will:  \n",
    "- Inspect a sample of emails to verify that the `body` field contains the actual message rather than residual headers.  \n",
    "- Cross-check the raw `message` text for cases where header fields (e.g., `to`) are null, and attempt to recover these values if possible.  \n",
    "\n",
    "This step ensures that the dataset is **accurately structured** before proceeding to further cleaning and analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6e736ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample Email at index 3869:\n",
      "\n",
      "URL: http://www.newsisfree.com/click/-2,8655708,215/\n",
      "Date: 2002-10-08T03:30:58+01:00\n",
      "\n",
      "*Politics: *The Conservative leadership yesterday launched itself into a frenzy \n",
      "of self-reproach as it struggled to shed the image of Britain's \"nasty party\".\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Sample email 1\n",
    "random_index = np.random.randint(0, len(extracted_df))\n",
    "print(f\"Random Sample Email at index {random_index}:\\n\")\n",
    "print(extracted_df['body'][random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "58cec428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample Email at index 2646:\n",
      "\n",
      "Just got this ... I was just reading mail, but in a very dark\n",
      "room, where the keyboard is illuminated mostly by the light from\n",
      "the (laptop) screen.   I think I put my fingers on the wrong keys.\n",
      "(I mostly use the keyboard exclusively while running exmh).\n",
      "\n",
      "This is from today's cvs (the fixes for the problems I mentioned\n",
      "yesterday are included) - I eventually managed to contact the cvs\n",
      "server.\n",
      "\n",
      "expected integer but got \"\"\n",
      "    while executing\n",
      "\"incr m\"\n",
      "    (procedure \"MhSeqExpand\" line 12)\n",
      "    invoked from within\n",
      "\"MhSeqExpand $folder $msgids\"\n",
      "    (procedure \"MhSeq\" line 2)\n",
      "    invoked from within\n",
      "\"MhSeq $folder $seq $how $oldmsgids $msgids\"\n",
      "    (procedure \"Mh_SequenceUpdate\" line 54)\n",
      "    invoked from within     \n",
      "\"Mh_SequenceUpdate $folder replace $seq $msgids\"\n",
      "    (procedure \"Seq_Set\" line 4)\n",
      "    invoked from within             \n",
      "\"Seq_Set $folder cur $msgid\"\n",
      "    (procedure \"Mh_SetCur\" line 7)      \n",
      "    invoked from within                     \n",
      "\"Mh_SetCur $exmh(folder) $msgid\"\n",
      "    (procedure \"MsgChange\" line 5)              \n",
      "    invoked from within                             \n",
      "\"MsgChange - noshow\"\n",
      "    invoked from within                                 \n",
      "\"time [list MsgChange $msgid $show\"\n",
      "    (procedure \"Msg_Change\" line 3)\n",
      "    invoked from within                                     \n",
      "\"Msg_Change $select(sel) noshow\"\n",
      "    (procedure \"SelectTypein\" line 14)                          \n",
      "    invoked from within\n",
      "\"SelectTypein .mid.right.top.msg -\"\n",
      "    (command bound to event)\n",
      "\n",
      "kre\n",
      "\n",
      "ps: I have the sequences window vertical instead of horizontal, and the\n",
      "\"colours from the ftoc\" stuff all deleted, and it is looking just about as\n",
      "good as the old unseen window used to look.   I still have some work to\n",
      "do to make it a little nicer (listboxes seem to have some strange habits)\n",
      "and then I need to make it all optional and parameterized, at the minute\n",
      "I'm just embedding stuff in the code, much quicker for prototyping.  Once\n",
      "its done, I'll send a patch for someone to look over.\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "Exmh-workers mailing list\n",
      "Exmh-workers@redhat.com\n",
      "https://listman.redhat.com/mailman/listinfo/exmh-workers\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Sample email 2\n",
    "random_index = np.random.randint(0, len(extracted_df))\n",
    "print(f\"Random Sample Email at index {random_index}:\\n\")\n",
    "print(extracted_df['body'][random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "12b5ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample Email at index 209:\n",
      "\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "   <title>The Soft2Reg Team</title>\n",
      "</head>\n",
      "<link rel=STYLESHEET type=text/css href=css/main.css>\n",
      "<STYLE type=text/css>\n",
      ".Black11 {FONT-SIZE: 11px; COLOR: black; FONT-FAMILY: Verdana;  FONT-WEIGHT: normal; TEXT-DECORATION: none}\n",
      ".Red13 {font-size : 13px; font-family :Verdana, Arial, Helvetica, sans-serif;font-weight : bold;color : Red}\n",
      "</style>\n",
      "\n",
      "<body bgcolor=ffffff>\n",
      "<center>\n",
      "<table border=0 width=600 cellpadding=2 cellspacing=0>\n",
      "\t<tr>\n",
      "\t\t<td width=275>\n",
      "\t\t\t<a href=http://www.soft2reg.com>\n",
      "\t\t\t\t<img src=http://www.soft2reg.com/images/logo.gif border=0 alt=www.soft2reg ></a>\n",
      "\t\t</td>\n",
      "\t\t<td align=right width=100%>\n",
      "\t\t\t<hr size=0>\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "</table>\n",
      "<p>\n",
      "<table border=0 width=600 cellpadding=4 cellspacing=0 bgcolor=6699cc>\n",
      "\t<tr>\n",
      "\t\t<td>\n",
      "\t\t\t<font face=arial size=+1 color=000000>\n",
      "\t\t\t\t<b>Soft2reg.com -- Service Update</b></font>\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "</table>\n",
      "<p>\n",
      "<table border=0 width=600 cellpadding=4 cellspacing=0>\n",
      "\t<tr>\n",
      "\t\t<td class=Black11>\n",
      "\t\t\tHello,<br><br>\n",
      "\n",
      "\t\t\t<br>We apologize for the unsolicited e-mail, \n",
      "\t\t\t\tbut we have noticed that you are using an online credit card processor on your web \n",
      "\t\t\t\tsite that charges you much more than what you should be paying.\n",
      "\n",
      " \t\t\t<br><br>\n",
      "\t\t\t\tWe are Soft2Reg.com and we <b>specialize in low cost online credit \n",
      "\t\t\t\tcard processing for developers of electronic products</b>. \n",
      "\t\t\t\tOur rates are the lowest in the industry - <span class=Red13>8% flat fee</span> for all online credit card transactions. \n",
      "\t\t\t\tWe provide you with a link for every one of your products that contains your logo and you put it on your web site for seamless credit card processing integration. For that simple, yet efficient service we charge only 8% of your online sales.\n",
      " \t\t\t\n",
      "\t\t\t<br><br>\n",
      "\t\t\tIf you would like to see more information about us, please visit <a href=http://www.soft2reg.com>http://www.soft2reg.com</a>.\n",
      "\t\t\t<br><br>\n",
      "\t\t\t<HR noShade SIZE=1>\n",
      "\t\t\t<br>Thank you,\n",
      "\t\t\t<br>The Soft2Reg Team\n",
      "\t\t\t<br>-----------------------------------\n",
      "\t\t\t<br><a href=http://www.soft2reg.com>www.soft2reg.com</a>.\n",
      "</td></tr></table>\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Sample email 3\n",
    "random_index = np.random.randint(0, len(extracted_df))\n",
    "print(f\"Random Sample Email at index {random_index}:\\n\")\n",
    "print(extracted_df['body'][random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1932e69",
   "metadata": {},
   "source": [
    "From the review of three sample emails, no major issues were identified. However, with over 4,000 emails in the dataset, manual inspection is not feasible. To ensure data quality, we will implement an automated validation process to:  \n",
    "\n",
    "- Move any existing headers (if spotted) into their respective dataframe columns.  \n",
    "- Extract the main body message.  \n",
    "\n",
    "This process will produce a cleaned, standardized dataset that is ready for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fc096a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled \"label\" in 0 rows.\n",
      "Filled \"message\" in 0 rows.\n",
      "Filled \"message_id\" in 0 rows.\n",
      "Filled \"date\" in 0 rows.\n",
      "Filled \"from\" in 0 rows.\n",
      "Filled \"to\" in 4 rows.\n",
      "Filled \"subject\" in 1 rows.\n",
      "Filled \"sender\" in 1 rows.\n",
      "Filled \"list_id\" in 1 rows.\n",
      "Filled \"body\" in 0 rows.\n"
     ]
    }
   ],
   "source": [
    "# Regex: normal headers that should not appear in the body\n",
    "HEADER_RE = re.compile(\n",
    "    r'^(return-path|delivered-to|message-id|date|from|to|subject|sender|errors-to|list-id)\\s*:',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# mapping header names -> df column names\n",
    "HEADER_TO_COL = {\n",
    "    \"message-id\": \"message_id\",\n",
    "    \"date\": \"date\",\n",
    "    \"from\": \"from\",\n",
    "    \"to\": \"to\",\n",
    "    \"subject\": \"subject\",\n",
    "    \"sender\": \"sender\",\n",
    "    \"list-id\": \"list_id\",\n",
    "}\n",
    "\n",
    "# Function to detect and extract body or  headers from email text\n",
    "def extract_info(text):\n",
    "    \"\"\"\n",
    "    Detect and Extract body from an email and recover any headers that leaked into it.\n",
    "    Steps:\n",
    "      1) Normalize line endings and split lines.\n",
    "      2) Body starts after the first blank line (end of header block).\n",
    "      3) Remove any header-like lines from the body.\n",
    "      4) Return (clean_body, recovered_headers_dict).\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\", {}\n",
    "\n",
    "    # Normalize line endings \n",
    "    text = str(text).replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "    # Split into lines\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # find the first blank line in the email text\n",
    "    header_end = -1  # default: assume no blank line (header/body split not found yet)\n",
    "    \n",
    "    # look for the first blank line\n",
    "    for i, ln in enumerate(lines):\n",
    "        if ln.strip() == \"\":\n",
    "            header_end = i     # record the index of the blank line\n",
    "            break              # stop at the first blank line\n",
    "\n",
    "    # body_lines = everything after the header block\n",
    "    if header_end >= 0:\n",
    "        # found a blank line → body starts just after that line\n",
    "        body_lines = lines[header_end + 1:]\n",
    "    else:\n",
    "        # no blank line found → treat the whole thing as body\n",
    "        body_lines = lines\n",
    "\n",
    "    # Initialize storage for recovered headers and cleaned body lines\n",
    "    recovered = {}\n",
    "    keep = []\n",
    "\n",
    "    # process body lines\n",
    "    for ln in body_lines:\n",
    "        ls = ln.strip()\n",
    "\n",
    "        # header-like line inside body\n",
    "        m = HEADER_RE.match(ls)\n",
    "        if m:\n",
    "            hdr = m.group(1).lower()\n",
    "            \n",
    "            # ls is the current line stripped of whitespace\n",
    "            if \":\" in ls:\n",
    "                # split into at most 2 parts: [before_colon, after_colon]\n",
    "                parts = ls.split(\":\", 1)\n",
    "                # take the right-hand side (after the first colon)\n",
    "                val = parts[1].strip()\n",
    "            else:\n",
    "                # if somehow there is no colon, fallback to empty string\n",
    "                val = \"\"\n",
    "\n",
    "            recovered[hdr] = val\n",
    "            continue    # skip this line (do not keep it in body)\n",
    "        \n",
    "        # keep everything else\n",
    "        keep.append(ln)\n",
    "\n",
    "    # return cleaned body and any recovered headers\n",
    "    clean_body = \"\\n\".join(keep).strip()\n",
    "    return clean_body, recovered\n",
    "\n",
    "# Helper to check if a cell is empty (NA or whitespace)\n",
    "def is_empty(cell):\n",
    "    \"\"\"True if cell is NA or only whitespace.\"\"\"\n",
    "\n",
    "    # check for NA\n",
    "    if pd.isna(cell):\n",
    "        return True\n",
    "    \n",
    "    # check for empty or whitespace-only string\n",
    "    if isinstance(cell, str) and cell.strip() == \"\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to clean email bodies and backfill missing headers into DataFrame\n",
    "def apply_data(df, col_body=\"body\"):\n",
    "    \"\"\"\n",
    "    - Clean df[col_body] so it has ONLY the body (no headers, no ***** lines).\n",
    "    - Write recovered headers into matching columns if those columns exist.\n",
    "    - Return a dict with counts of how many cells were filled per header column.\n",
    "    \"\"\"\n",
    "    # Initialize storage for cleaned bodies and fill counts \n",
    "    clean_bodies = []\n",
    "    fill_counts = {col: 0 for col in df.columns if col in df.columns}\n",
    "\n",
    "    # process each email body\n",
    "    for i, msg in enumerate(df[col_body]):\n",
    "        # extract clean body and any recovered headers\n",
    "        body_clean, recovered = extract_info(msg)\n",
    "        clean_bodies.append(body_clean)\n",
    "\n",
    "        # backfill headers only into existing columns in your df\n",
    "        for hdr, col in HEADER_TO_COL.items():\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            val = recovered.get(hdr)\n",
    "\n",
    "            if val is None:\n",
    "                continue\n",
    "\n",
    "            # only fill if the cell is empty\n",
    "            if is_empty(df.at[i, col]):\n",
    "\n",
    "                # if the recovered value is a list, join with newlines\n",
    "                if isinstance(val, list):\n",
    "                    df.at[i, col] = \"\\n---\\n\".join(val)\n",
    "\n",
    "                # otherwise just fill the string value\n",
    "                else:\n",
    "                    df.at[i, col] = val\n",
    "                fill_counts[col] += 1\n",
    "\n",
    "    # update the body column with cleaned bodies\n",
    "    df[col_body] = clean_bodies\n",
    "\n",
    "    return fill_counts\n",
    "\n",
    "# clean the body and backfill any missing headers and also count how many cells were filled per column\n",
    "fill_counts = apply_data(extracted_df, col_body=\"body\")\n",
    "\n",
    "# print how many cells were filled per column\n",
    "for col, count in fill_counts.items():\n",
    "    print(f\"Filled \\\"{col}\\\" in {count} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2850275",
   "metadata": {},
   "source": [
    "#### URL Extraction\n",
    "\n",
    "Next, we extract all URLs contained in the email bodies.  \n",
    "\n",
    "URLs are important for phishing detection because suspicious or malicious links are often key indicators of phishing attempts.  \n",
    "\n",
    "By isolating the URLs, we can analyze them separately and apply rules to identify potentially harmful links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract URLs from dataset['message'] directly\n",
    "def extract_urls_from_message(raw_msg):\n",
    "    \n",
    "    # Ensure the input is a string\n",
    "    if not isinstance(raw_msg, str):\n",
    "        return None\n",
    "    \n",
    "    # Regex pattern to match URLs (http or https)\n",
    "    url_pattern = r'(https?://[^\\s,)\\]>]+)'\n",
    "\n",
    "    # Find all URLs in the raw message\n",
    "    urls = re.findall(url_pattern, raw_msg)\n",
    "\n",
    "    return urls if urls else None\n",
    "\n",
    "# apply directly on the raw message column\n",
    "extracted_df['urls'] = data_ds['message'].apply(extract_urls_from_message)\n",
    "extracted_df['num_urls'] = extracted_df['urls'].apply(lambda x: len(x) if x is not None else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7367887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>list_id</th>\n",
       "      <th>body</th>\n",
       "      <th>urls</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...</td>\n",
       "      <td>&lt;1028311679.886@0.57.142&gt;</td>\n",
       "      <td>Fri, 02 Aug 2002 23:37:59 0530</td>\n",
       "      <td>\"Start Now\" &lt;startnow2002@hotmail.com&gt;</td>\n",
       "      <td>ilug@linux.ie</td>\n",
       "      <td>[ILUG] STOP THE MLM INSANITY</td>\n",
       "      <td>ilug-admin@linux.ie</td>\n",
       "      <td>Irish Linux Users' Group &lt;ilug.linux.ie&gt;</td>\n",
       "      <td>You are receiving this letter because you have...</td>\n",
       "      <td>[http://www.linux.ie/mailman/listinfo/ilug]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...</td>\n",
       "      <td>&lt;B0000178595@203.129.205.5.205.129.203.in-addr...</td>\n",
       "      <td>Mon, 28 Jul 1980 14:01:35</td>\n",
       "      <td>lmrn@mailexcite.com</td>\n",
       "      <td>ranmoore@cybertime.net</td>\n",
       "      <td>Real Protection, Stun Guns!  Free Shipping! Ti...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;/b&gt;\\n&lt;/font&gt;\\n&lt;/h3&gt;\\n&lt;/center&gt;\\n&lt;p&gt;\\nIT'S GET...</td>\n",
       "      <td>[http://www.geocities.com/realprotection_20022...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>From amknight@mailexcite.com  Mon Jun 24 17:03...</td>\n",
       "      <td>&lt;0845b5355070f52WEBCUST2@webcust2.hightowertec...</td>\n",
       "      <td>Wed, 30 Jul 1980 18:25:49</td>\n",
       "      <td>amknight@mailexcite.com</td>\n",
       "      <td>cbmark@cbmark.com</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;font color=\"blue\"&gt;\\n\\nLOSE 30 POUNDS  IN 30 D...</td>\n",
       "      <td>[http://www.geocities.com/ultra_weightloss_200...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>From jordan23@mailexcite.com  Mon Jun 24 17:04...</td>\n",
       "      <td>&lt;0925c5750200f52WEBCUST2@webcust2.hightowertec...</td>\n",
       "      <td>Thu, 31 Jul 1980 07:20:54</td>\n",
       "      <td>jordan23@mailexcite.com</td>\n",
       "      <td>ranmoore@swbell.net</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;font color=\"blue\"&gt;\\n\\nLOSE 30 POUNDS  IN 30 D...</td>\n",
       "      <td>[http://www.geocities.com/ultra_weightloss_200...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>From merchantsworld2001@juno.com  Tue Aug  6 1...</td>\n",
       "      <td>&lt;200208040037.BAA09623@webnote.net&gt;</td>\n",
       "      <td>Sun, 19 Oct 1980 10:55:16</td>\n",
       "      <td>yyyy@pluriproj.pt</td>\n",
       "      <td>yyyy@pluriproj.pt</td>\n",
       "      <td>Never Repay Cash Grants, $500 - $50,000, Secre...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;li&gt;Every day &lt;b&gt;&lt;font color = \"green\"&gt;million...</td>\n",
       "      <td>[http://www.geocities.com/grantzone_2002/\", ht...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      1  From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...   \n",
       "1      1  From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...   \n",
       "2      1  From amknight@mailexcite.com  Mon Jun 24 17:03...   \n",
       "3      1  From jordan23@mailexcite.com  Mon Jun 24 17:04...   \n",
       "4      1  From merchantsworld2001@juno.com  Tue Aug  6 1...   \n",
       "\n",
       "                                          message_id  \\\n",
       "0                          <1028311679.886@0.57.142>   \n",
       "1  <B0000178595@203.129.205.5.205.129.203.in-addr...   \n",
       "2  <0845b5355070f52WEBCUST2@webcust2.hightowertec...   \n",
       "3  <0925c5750200f52WEBCUST2@webcust2.hightowertec...   \n",
       "4                <200208040037.BAA09623@webnote.net>   \n",
       "\n",
       "                             date                                    from  \\\n",
       "0  Fri, 02 Aug 2002 23:37:59 0530  \"Start Now\" <startnow2002@hotmail.com>   \n",
       "1       Mon, 28 Jul 1980 14:01:35                     lmrn@mailexcite.com   \n",
       "2       Wed, 30 Jul 1980 18:25:49                 amknight@mailexcite.com   \n",
       "3       Thu, 31 Jul 1980 07:20:54                 jordan23@mailexcite.com   \n",
       "4       Sun, 19 Oct 1980 10:55:16                       yyyy@pluriproj.pt   \n",
       "\n",
       "                       to                                            subject  \\\n",
       "0           ilug@linux.ie                       [ILUG] STOP THE MLM INSANITY   \n",
       "1  ranmoore@cybertime.net  Real Protection, Stun Guns!  Free Shipping! Ti...   \n",
       "2       cbmark@cbmark.com  New Improved Fat Burners, Now With TV Fat Abso...   \n",
       "3     ranmoore@swbell.net  New Improved Fat Burners, Now With TV Fat Abso...   \n",
       "4       yyyy@pluriproj.pt  Never Repay Cash Grants, $500 - $50,000, Secre...   \n",
       "\n",
       "                sender                                   list_id  \\\n",
       "0  ilug-admin@linux.ie  Irish Linux Users' Group <ilug.linux.ie>   \n",
       "1                 None                                      None   \n",
       "2                 None                                      None   \n",
       "3                 None                                      None   \n",
       "4                 None                                      None   \n",
       "\n",
       "                                                body  \\\n",
       "0  You are receiving this letter because you have...   \n",
       "1  </b>\\n</font>\\n</h3>\\n</center>\\n<p>\\nIT'S GET...   \n",
       "2  <font color=\"blue\">\\n\\nLOSE 30 POUNDS  IN 30 D...   \n",
       "3  <font color=\"blue\">\\n\\nLOSE 30 POUNDS  IN 30 D...   \n",
       "4  <li>Every day <b><font color = \"green\">million...   \n",
       "\n",
       "                                                urls  num_urls  \n",
       "0        [http://www.linux.ie/mailman/listinfo/ilug]         1  \n",
       "1  [http://www.geocities.com/realprotection_20022...         4  \n",
       "2  [http://www.geocities.com/ultra_weightloss_200...         4  \n",
       "3  [http://www.geocities.com/ultra_weightloss_200...         4  \n",
       "4  [http://www.geocities.com/grantzone_2002/\", ht...         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows to verify extraction\n",
    "display(extracted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b6601",
   "metadata": {},
   "source": [
    "Based on the extracted dataset, all key headers, the email body, and URLs have been successfully captured and standardized. The `body` field is readable and normalized, while `message_id` preserves its original format. Although this sample shows no URLs, the dataset is structured to capture them if present in other emails.  \n",
    "\n",
    "### Text Cleaning\n",
    "\n",
    "In this step, we clean the relevant text fields in the dataset to prepare for analysis and phishing detection.  \n",
    "\n",
    "The cleaning process includes:\n",
    "\n",
    "1. **Removing content inside angle brackets (`<...>`)** for all columns except `message_id`  \n",
    "   - Standardizes email addresses and header fields.  \n",
    "\n",
    "2. **Normalizing whitespace and removing unwanted content**  \n",
    "   - Replace multiple spaces, tabs, and newlines with a single space.  \n",
    "   - Remove leading and trailing spaces.  \n",
    "   - Remove separator lines such as `----------` and `************`.  \n",
    "   - Remove embedded HTML code.  \n",
    "\n",
    "3. **Reordering and dropping columns**  \n",
    "   - Adjust column order to match the workflow for phishing detection.  \n",
    "   - Drop any unnecessary or redundant columns to simplify the dataset.  \n",
    "   - This makes the dataset more organized and easier to work with in subsequent steps.  \n",
    "\n",
    "This process ensures all text fields are **clean, consistent, and ready** for further processing, while preserving important information for phishing detection, including URLs, attachments, and non-ASCII characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "afa85905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to prevent mutation\n",
    "final_df = extracted_df.copy()\n",
    "\n",
    "# Function to clean text fields for phishing detection analysis\n",
    "def clean_text(x, keep_tags=False):\n",
    "    \"\"\"\n",
    "    Clean text fields for phishing detection analysis.\n",
    "\n",
    "    Steps:\n",
    "    1. Collapse whitespace.\n",
    "    2. Remove <...> entirely unless keep_tags=True (preserve for message_id).\n",
    "    3. Remove [] but keep the content inside.\n",
    "    4. Remove quotes ' and \".\n",
    "    5. Remove common separator lines: ----------, ************.\n",
    "    6. Remove embedded HTML tags.\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return None  # No change\n",
    "\n",
    "    text = str(x)\n",
    "\n",
    "    # Remove <...> unless we want to keep tags (e.g., message_id)\n",
    "    if not keep_tags:\n",
    "        text = re.sub(r'<[^>]*>', '', text)  \n",
    "\n",
    "    # Remove separator lines\n",
    "    text = re.sub(r'[-*]{4,}', ' ', text)  # sequences of 4+ - or *\n",
    "\n",
    "    # Remove brackets [] but keep content inside\n",
    "    text = re.sub(r'[\\[\\]]+', '', text)\n",
    "\n",
    "    # Remove quotes ' and \"\n",
    "    text = re.sub(r\"[\\'\\\"]+\", '', text)\n",
    "\n",
    "    # Collapse multiple spaces, tabs, newlines into a single space, and strip\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# NEW: helper to normalize address fields (From / To / Sender)\n",
    "EMAIL_RE = re.compile(r'[A-Z0-9._%+\\-]+@[A-Z0-9.\\-]+\\.[A-Z]{2,}', re.IGNORECASE)\n",
    "\n",
    "# Normalize email address fields\n",
    "def normalize_address_field(x):\n",
    "    \"\"\"\n",
    "    Return only the email(s). If <...> present, prefer those.\n",
    "    If multiple addresses, join with ', '.\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x)\n",
    "\n",
    "    # Prefer emails inside <...>\n",
    "    in_angles = re.findall(r'<\\s*([^<>@\\s]+@[^<>@\\s]+)\\s*>', s)\n",
    "    if in_angles:\n",
    "        return ', '.join(e.strip() for e in in_angles)\n",
    "\n",
    "    # Fallback: any email-looking substrings\n",
    "    any_emails = EMAIL_RE.findall(s)\n",
    "    if any_emails:\n",
    "        return ', '.join(e.strip() for e in any_emails)\n",
    "\n",
    "    # If nothing matched, return cleaned plain text\n",
    "    return clean_text(s)\n",
    "\n",
    "# Apply cleaning to relevant columns\n",
    "columns_to_clean = ['message_id', 'date', 'from', 'to', 'subject','sender', 'list_id', 'body', 'urls']\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    if col in ('from', 'to', 'sender'):\n",
    "        final_df[col] = final_df[col].apply(normalize_address_field)\n",
    "    elif col == 'message_id':\n",
    "        final_df[col] = final_df[col].apply(lambda x: clean_text(x, keep_tags=True))\n",
    "    else:\n",
    "        final_df[col] = final_df[col].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2a9b786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired column order\n",
    "cols = ['message_id', 'date', 'from', 'to', 'subject', 'sender', 'list_id', 'body', 'urls', 'num_urls', 'label']\n",
    "\n",
    "# Drop the unnecessary column and rearranging columns for better readability\n",
    "final_df = final_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2a00edd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>list_id</th>\n",
       "      <th>body</th>\n",
       "      <th>urls</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;1028311679.886@0.57.142&gt;</td>\n",
       "      <td>Fri, 02 Aug 2002 23:37:59 0530</td>\n",
       "      <td>startnow2002@hotmail.com</td>\n",
       "      <td>ilug@linux.ie</td>\n",
       "      <td>ILUG STOP THE MLM INSANITY</td>\n",
       "      <td>ilug-admin@linux.ie</td>\n",
       "      <td>Irish Linux Users Group</td>\n",
       "      <td>You are receiving this letter because you have...</td>\n",
       "      <td>http://www.linux.ie/mailman/listinfo/ilug</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;B0000178595@203.129.205.5.205.129.203.in-addr...</td>\n",
       "      <td>Mon, 28 Jul 1980 14:01:35</td>\n",
       "      <td>lmrn@mailexcite.com</td>\n",
       "      <td>ranmoore@cybertime.net</td>\n",
       "      <td>Real Protection, Stun Guns! Free Shipping! Tim...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ITS GETTING TO BE SPRING AGAIN, PROTECT YOURSE...</td>\n",
       "      <td>http://www.geocities.com/realprotection_200220...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;0845b5355070f52WEBCUST2@webcust2.hightowertec...</td>\n",
       "      <td>Wed, 30 Jul 1980 18:25:49</td>\n",
       "      <td>amknight@mailexcite.com</td>\n",
       "      <td>cbmark@cbmark.com</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOSE 30 POUNDS IN 30 DAYS... GUARANTEED!!! All...</td>\n",
       "      <td>http://www.geocities.com/ultra_weightloss_2002...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;0925c5750200f52WEBCUST2@webcust2.hightowertec...</td>\n",
       "      <td>Thu, 31 Jul 1980 07:20:54</td>\n",
       "      <td>jordan23@mailexcite.com</td>\n",
       "      <td>ranmoore@swbell.net</td>\n",
       "      <td>New Improved Fat Burners, Now With TV Fat Abso...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOSE 30 POUNDS IN 30 DAYS... GUARANTEED!!! All...</td>\n",
       "      <td>http://www.geocities.com/ultra_weightloss_2002...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;200208040037.BAA09623@webnote.net&gt;</td>\n",
       "      <td>Sun, 19 Oct 1980 10:55:16</td>\n",
       "      <td>yyyy@pluriproj.pt</td>\n",
       "      <td>yyyy@pluriproj.pt</td>\n",
       "      <td>Never Repay Cash Grants, $500 - $50,000, Secre...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Every day millions of dollars are given away t...</td>\n",
       "      <td>http://www.geocities.com/grantzone_2002/, http...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          message_id  \\\n",
       "0                          <1028311679.886@0.57.142>   \n",
       "1  <B0000178595@203.129.205.5.205.129.203.in-addr...   \n",
       "2  <0845b5355070f52WEBCUST2@webcust2.hightowertec...   \n",
       "3  <0925c5750200f52WEBCUST2@webcust2.hightowertec...   \n",
       "4                <200208040037.BAA09623@webnote.net>   \n",
       "\n",
       "                             date                      from  \\\n",
       "0  Fri, 02 Aug 2002 23:37:59 0530  startnow2002@hotmail.com   \n",
       "1       Mon, 28 Jul 1980 14:01:35       lmrn@mailexcite.com   \n",
       "2       Wed, 30 Jul 1980 18:25:49   amknight@mailexcite.com   \n",
       "3       Thu, 31 Jul 1980 07:20:54   jordan23@mailexcite.com   \n",
       "4       Sun, 19 Oct 1980 10:55:16         yyyy@pluriproj.pt   \n",
       "\n",
       "                       to                                            subject  \\\n",
       "0           ilug@linux.ie                         ILUG STOP THE MLM INSANITY   \n",
       "1  ranmoore@cybertime.net  Real Protection, Stun Guns! Free Shipping! Tim...   \n",
       "2       cbmark@cbmark.com  New Improved Fat Burners, Now With TV Fat Abso...   \n",
       "3     ranmoore@swbell.net  New Improved Fat Burners, Now With TV Fat Abso...   \n",
       "4       yyyy@pluriproj.pt  Never Repay Cash Grants, $500 - $50,000, Secre...   \n",
       "\n",
       "                sender                  list_id  \\\n",
       "0  ilug-admin@linux.ie  Irish Linux Users Group   \n",
       "1                 None                     None   \n",
       "2                 None                     None   \n",
       "3                 None                     None   \n",
       "4                 None                     None   \n",
       "\n",
       "                                                body  \\\n",
       "0  You are receiving this letter because you have...   \n",
       "1  ITS GETTING TO BE SPRING AGAIN, PROTECT YOURSE...   \n",
       "2  LOSE 30 POUNDS IN 30 DAYS... GUARANTEED!!! All...   \n",
       "3  LOSE 30 POUNDS IN 30 DAYS... GUARANTEED!!! All...   \n",
       "4  Every day millions of dollars are given away t...   \n",
       "\n",
       "                                                urls  num_urls  label  \n",
       "0          http://www.linux.ie/mailman/listinfo/ilug         1      1  \n",
       "1  http://www.geocities.com/realprotection_200220...         4      1  \n",
       "2  http://www.geocities.com/ultra_weightloss_2002...         4      1  \n",
       "3  http://www.geocities.com/ultra_weightloss_2002...         4      1  \n",
       "4  http://www.geocities.com/grantzone_2002/, http...         2      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the cleaned dataframe\n",
    "display(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d039e",
   "metadata": {},
   "source": [
    "final### Post-Parsing Data Validation\n",
    "\n",
    "After parsing and splitting the emails into separate columns, it is important to verify the integrity of the new dataset.  \n",
    "\n",
    "We will:\n",
    "\n",
    "1. **Inspect dataset summary** – Using `data.info()` to review column names, data types, and non-null counts.  \n",
    "2. **Check for null values** – Some fields such as `subject` or `body` may be empty even if the original message was not null.  \n",
    "3. **Check for duplicate rows** – Parsing may create redundant entries that should be removed.  \n",
    "\n",
    "These steps ensure that the parsed dataset is **clean, consistent, and ready** for further analysis and phishing detection.\n",
    "\n",
    "#### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b748219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4178 entries, 0 to 4177\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   message_id  4176 non-null   object\n",
      " 1   date        4177 non-null   object\n",
      " 2   from        4177 non-null   object\n",
      " 3   to          4012 non-null   object\n",
      " 4   subject     4176 non-null   object\n",
      " 5   sender      1978 non-null   object\n",
      " 6   list_id     1723 non-null   object\n",
      " 7   body        4178 non-null   object\n",
      " 8   urls        3767 non-null   object\n",
      " 9   num_urls    4178 non-null   int64 \n",
      " 10  label       4178 non-null   int64 \n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 359.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the info of cleaned dataframe\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e29f8",
   "metadata": {},
   "source": [
    "##### Handling of Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "130979b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body             0\n",
      "num_urls         0\n",
      "label            0\n",
      "date             1\n",
      "from             1\n",
      "message_id       2\n",
      "subject          2\n",
      "to             166\n",
      "urls           411\n",
      "sender        2200\n",
      "list_id       2455\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "print(final_df.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41661d",
   "metadata": {},
   "source": [
    "##### Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "425316dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing duplicates: (4178, 11)\n",
      "Shape after removing duplicates: (4090, 11)\n"
     ]
    }
   ],
   "source": [
    "# shape of dataset before removing duplicates\n",
    "print(f\"Shape before removing duplicates: {final_df.shape}\")\n",
    "\n",
    "# Removing duplicate rows\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Shape of dataset after removing duplicates\n",
    "print(f\"Shape after removing duplicates: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9c71d",
   "metadata": {},
   "source": [
    "# Save the cleaned dataset\n",
    "After checking for duplicates and adding the label column, the cleaned dataset is saved to a CSV file for later processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0de0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file named 'cleaned_SA.csv'\n",
    "final_df.to_csv('cleaned_SA.csv', index=False) # The index=False ensures the index is not saved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
